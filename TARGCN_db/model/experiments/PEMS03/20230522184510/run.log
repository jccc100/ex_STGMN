2023-05-22 18:45: Experiment log path in: C:\Users\Jesse\Desktop\´ð±ç\Traffic_models\TARGCN_db\model\experiments\PEMS03\20230522184510
2023-05-22 18:45: Train Epoch 0: 0/490 Loss: 191.658142
2023-05-22 18:45: Train Epoch 0: 20/490 Loss: 129.769928
2023-05-22 18:45: Train Epoch 0: 40/490 Loss: 154.248398
2023-05-22 18:45: Train Epoch 0: 60/490 Loss: 139.447327
2023-05-22 18:45: Train Epoch 0: 80/490 Loss: 94.518616
2023-05-22 18:45: Train Epoch 0: 100/490 Loss: 104.948540
2023-05-22 18:45: Train Epoch 0: 120/490 Loss: 74.272118
2023-05-22 18:45: Train Epoch 0: 140/490 Loss: 81.049164
2023-05-22 18:45: Train Epoch 0: 160/490 Loss: 57.559982
2023-05-22 18:45: Train Epoch 0: 180/490 Loss: 57.461220
2023-05-22 18:45: Train Epoch 0: 200/490 Loss: 41.103512
2023-05-22 18:45: Train Epoch 0: 220/490 Loss: 37.785854
2023-05-22 18:46: Train Epoch 0: 240/490 Loss: 39.960167
2023-05-22 18:46: Train Epoch 0: 260/490 Loss: 38.630238
2023-05-22 18:46: Train Epoch 0: 280/490 Loss: 30.374786
2023-05-22 18:46: Train Epoch 0: 300/490 Loss: 25.831533
2023-05-22 18:46: Train Epoch 0: 320/490 Loss: 31.618414
2023-05-22 18:46: Train Epoch 0: 340/490 Loss: 25.587015
2023-05-22 18:46: Train Epoch 0: 360/490 Loss: 24.995853
2023-05-22 18:46: Train Epoch 0: 380/490 Loss: 24.026035
2023-05-22 18:46: Train Epoch 0: 400/490 Loss: 30.923098
2023-05-22 18:46: Train Epoch 0: 420/490 Loss: 20.845886
2023-05-22 18:46: Train Epoch 0: 440/490 Loss: 19.733866
2023-05-22 18:46: Train Epoch 0: 460/490 Loss: 23.540926
2023-05-22 18:46: Train Epoch 0: 480/490 Loss: 18.357288
2023-05-22 18:46: **********Train Epoch 0: averaged Loss: 60.034602, tf_ratio: 1.000000
2023-05-22 18:47: **********Val Epoch 0: average Loss: 21.712462
2023-05-22 18:47: ******Current best model saved:model_para/PEMS03/epoch_0.pth!
2023-05-22 18:47: Train Epoch 1: 0/490 Loss: 21.243580
2023-05-22 18:47: Train Epoch 1: 20/490 Loss: 20.389181
2023-05-22 18:47: Train Epoch 1: 40/490 Loss: 22.643465
2023-05-22 18:47: Train Epoch 1: 60/490 Loss: 20.674578
2023-05-22 18:47: Train Epoch 1: 80/490 Loss: 21.304329
2023-05-22 18:47: Train Epoch 1: 100/490 Loss: 23.894253
2023-05-22 18:47: Train Epoch 1: 120/490 Loss: 23.622766
2023-05-22 18:47: Train Epoch 1: 140/490 Loss: 16.426102
2023-05-22 18:47: Train Epoch 1: 160/490 Loss: 22.353725
2023-05-22 18:47: Train Epoch 1: 180/490 Loss: 21.146923
2023-05-22 18:47: Train Epoch 1: 200/490 Loss: 20.310102
2023-05-22 18:47: Train Epoch 1: 220/490 Loss: 19.670925
2023-05-22 18:47: Train Epoch 1: 240/490 Loss: 20.012486
2023-05-22 18:48: Train Epoch 1: 260/490 Loss: 18.559464
2023-05-22 18:48: Train Epoch 1: 280/490 Loss: 20.933243
2023-05-22 18:48: Train Epoch 1: 300/490 Loss: 18.852455
2023-05-22 18:48: Train Epoch 1: 320/490 Loss: 19.448526
2023-05-22 18:48: Train Epoch 1: 340/490 Loss: 20.594791
2023-05-22 18:48: Train Epoch 1: 360/490 Loss: 22.232605
2023-05-22 18:48: Train Epoch 1: 380/490 Loss: 19.926516
2023-05-22 18:48: Train Epoch 1: 400/490 Loss: 17.075859
2023-05-22 18:48: Train Epoch 1: 420/490 Loss: 20.274870
2023-05-22 18:48: Train Epoch 1: 440/490 Loss: 22.750879
2023-05-22 18:48: Train Epoch 1: 460/490 Loss: 20.516237
2023-05-22 18:48: Train Epoch 1: 480/490 Loss: 19.054150
2023-05-22 18:48: **********Train Epoch 1: averaged Loss: 20.760994, tf_ratio: 1.000000
2023-05-22 18:49: **********Val Epoch 1: average Loss: 19.792689
2023-05-22 18:49: ******Current best model saved:model_para/PEMS03/epoch_1.pth!
2023-05-22 18:49: Train Epoch 2: 0/490 Loss: 20.213284
2023-05-22 18:49: Train Epoch 2: 20/490 Loss: 20.081125
2023-05-22 18:49: Train Epoch 2: 40/490 Loss: 17.442858
2023-05-22 18:49: Train Epoch 2: 60/490 Loss: 23.776459
2023-05-22 18:49: Train Epoch 2: 80/490 Loss: 20.613747
2023-05-22 18:49: Train Epoch 2: 100/490 Loss: 20.950253
2023-05-22 18:49: Train Epoch 2: 120/490 Loss: 20.245607
2023-05-22 18:49: Train Epoch 2: 140/490 Loss: 19.802814
2023-05-22 18:49: Train Epoch 2: 160/490 Loss: 20.295313
2023-05-22 18:49: Train Epoch 2: 180/490 Loss: 18.397940
2023-05-22 18:49: Train Epoch 2: 200/490 Loss: 19.303942
2023-05-22 18:49: Train Epoch 2: 220/490 Loss: 20.229910
2023-05-22 18:49: Train Epoch 2: 240/490 Loss: 19.532978
2023-05-22 18:50: Train Epoch 2: 260/490 Loss: 18.515884
2023-05-22 18:50: Train Epoch 2: 280/490 Loss: 20.362474
2023-05-22 18:50: Train Epoch 2: 300/490 Loss: 18.611298
2023-05-22 18:50: Train Epoch 2: 320/490 Loss: 17.866463
2023-05-22 18:50: Train Epoch 2: 340/490 Loss: 17.827717
2023-05-22 18:50: Train Epoch 2: 360/490 Loss: 18.079708
2023-05-22 18:50: Train Epoch 2: 380/490 Loss: 19.222210
2023-05-22 18:50: Train Epoch 2: 400/490 Loss: 19.646532
2023-05-22 18:50: Train Epoch 2: 420/490 Loss: 18.879374
2023-05-22 18:50: Train Epoch 2: 440/490 Loss: 19.421259
2023-05-22 18:50: Train Epoch 2: 460/490 Loss: 19.184179
2023-05-22 18:50: Train Epoch 2: 480/490 Loss: 17.353558
2023-05-22 18:50: **********Train Epoch 2: averaged Loss: 19.113261, tf_ratio: 1.000000
2023-05-22 18:51: **********Val Epoch 2: average Loss: 20.371169
2023-05-22 18:51: Train Epoch 3: 0/490 Loss: 22.281832
2023-05-22 18:51: Train Epoch 3: 20/490 Loss: 18.608477
2023-05-22 18:51: Train Epoch 3: 40/490 Loss: 16.570822
2023-05-22 18:51: Train Epoch 3: 60/490 Loss: 15.551210
2023-05-22 18:51: Train Epoch 3: 80/490 Loss: 17.072117
2023-05-22 18:51: Train Epoch 3: 100/490 Loss: 16.848400
2023-05-22 18:51: Train Epoch 3: 120/490 Loss: 16.968901
2023-05-22 18:51: Train Epoch 3: 140/490 Loss: 17.392807
2023-05-22 18:51: Train Epoch 3: 160/490 Loss: 18.314877
2023-05-22 18:51: Train Epoch 3: 180/490 Loss: 17.883139
2023-05-22 18:51: Train Epoch 3: 200/490 Loss: 18.829100
2023-05-22 18:51: Train Epoch 3: 220/490 Loss: 17.069849
2023-05-22 18:51: Train Epoch 3: 240/490 Loss: 16.276587
2023-05-22 18:51: Train Epoch 3: 260/490 Loss: 17.532162
2023-05-22 18:52: Train Epoch 3: 280/490 Loss: 17.214985
2023-05-22 18:52: Train Epoch 3: 300/490 Loss: 17.277254
2023-05-22 18:52: Train Epoch 3: 320/490 Loss: 18.994970
2023-05-22 18:52: Train Epoch 3: 340/490 Loss: 15.944158
2023-05-22 18:52: Train Epoch 3: 360/490 Loss: 16.603615
2023-05-22 18:52: Train Epoch 3: 380/490 Loss: 16.955282
2023-05-22 18:52: Train Epoch 3: 400/490 Loss: 17.041889
2023-05-22 18:52: Train Epoch 3: 420/490 Loss: 17.699778
2023-05-22 18:52: Train Epoch 3: 440/490 Loss: 18.967865
2023-05-22 18:52: Train Epoch 3: 460/490 Loss: 16.241247
2023-05-22 18:52: Train Epoch 3: 480/490 Loss: 13.768078
2023-05-22 18:52: **********Train Epoch 3: averaged Loss: 17.514504, tf_ratio: 1.000000
2023-05-22 18:52: **********Val Epoch 3: average Loss: 16.491018
2023-05-22 18:52: ******Current best model saved:model_para/PEMS03/epoch_3.pth!
2023-05-22 18:52: Train Epoch 4: 0/490 Loss: 17.052464
2023-05-22 18:53: Train Epoch 4: 20/490 Loss: 16.776304
2023-05-22 18:53: Train Epoch 4: 40/490 Loss: 16.859982
2023-05-22 18:53: Train Epoch 4: 60/490 Loss: 16.671312
2023-05-22 18:53: Train Epoch 4: 80/490 Loss: 17.824022
2023-05-22 18:53: Train Epoch 4: 100/490 Loss: 17.901001
2023-05-22 18:53: Train Epoch 4: 120/490 Loss: 17.776167
2023-05-22 18:53: Train Epoch 4: 140/490 Loss: 15.385451
2023-05-22 18:53: Train Epoch 4: 160/490 Loss: 17.756517
2023-05-22 18:53: Train Epoch 4: 180/490 Loss: 16.420214
2023-05-22 18:53: Train Epoch 4: 200/490 Loss: 17.019093
2023-05-22 18:53: Train Epoch 4: 220/490 Loss: 17.086708
2023-05-22 18:53: Train Epoch 4: 240/490 Loss: 16.171944
2023-05-22 18:53: Train Epoch 4: 260/490 Loss: 18.467445
2023-05-22 18:53: Train Epoch 4: 280/490 Loss: 16.845028
2023-05-22 18:54: Train Epoch 4: 300/490 Loss: 17.568640
2023-05-22 18:54: Train Epoch 4: 320/490 Loss: 15.209682
2023-05-22 18:54: Train Epoch 4: 340/490 Loss: 14.757867
2023-05-22 18:54: Train Epoch 4: 360/490 Loss: 15.284783
2023-05-22 18:54: Train Epoch 4: 380/490 Loss: 15.810105
2023-05-22 18:54: Train Epoch 4: 400/490 Loss: 16.329752
2023-05-22 18:54: Train Epoch 4: 420/490 Loss: 14.171381
2023-05-22 18:54: Train Epoch 4: 440/490 Loss: 16.660835
2023-05-22 18:54: Train Epoch 4: 460/490 Loss: 16.447098
2023-05-22 18:54: Train Epoch 4: 480/490 Loss: 16.158150
2023-05-22 18:54: **********Train Epoch 4: averaged Loss: 16.347848, tf_ratio: 1.000000
2023-05-22 18:54: **********Val Epoch 4: average Loss: 16.409570
2023-05-22 18:54: ******Current best model saved:model_para/PEMS03/epoch_4.pth!
2023-05-22 18:54: Train Epoch 5: 0/490 Loss: 16.409790
2023-05-22 18:54: Train Epoch 5: 20/490 Loss: 14.505248
2023-05-22 18:55: Train Epoch 5: 40/490 Loss: 17.217726
2023-05-22 18:55: Train Epoch 5: 60/490 Loss: 15.958521
2023-05-22 18:55: Train Epoch 5: 80/490 Loss: 14.456892
2023-05-22 18:55: Train Epoch 5: 100/490 Loss: 15.222641
2023-05-22 18:55: Train Epoch 5: 120/490 Loss: 14.442950
2023-05-22 18:55: Train Epoch 5: 140/490 Loss: 14.076957
2023-05-22 18:55: Train Epoch 5: 160/490 Loss: 16.184906
2023-05-22 18:55: Train Epoch 5: 180/490 Loss: 16.783072
2023-05-22 18:55: Train Epoch 5: 200/490 Loss: 16.582355
2023-05-22 18:55: Train Epoch 5: 220/490 Loss: 18.101110
2023-05-22 18:55: Train Epoch 5: 240/490 Loss: 16.500862
2023-05-22 18:55: Train Epoch 5: 260/490 Loss: 15.207734
2023-05-22 18:55: Train Epoch 5: 280/490 Loss: 16.106672
2023-05-22 18:55: Train Epoch 5: 300/490 Loss: 15.315766
2023-05-22 18:56: Train Epoch 5: 320/490 Loss: 15.366937
2023-05-22 18:56: Train Epoch 5: 340/490 Loss: 15.824694
2023-05-22 18:56: Train Epoch 5: 360/490 Loss: 17.136389
2023-05-22 18:56: Train Epoch 5: 380/490 Loss: 15.302927
2023-05-22 18:56: Train Epoch 5: 400/490 Loss: 13.288765
2023-05-22 18:56: Train Epoch 5: 420/490 Loss: 15.702172
2023-05-22 18:56: Train Epoch 5: 440/490 Loss: 16.607655
2023-05-22 18:56: Train Epoch 5: 460/490 Loss: 14.978271
2023-05-22 18:56: Train Epoch 5: 480/490 Loss: 16.786255
2023-05-22 18:56: **********Train Epoch 5: averaged Loss: 15.780196, tf_ratio: 1.000000
2023-05-22 18:56: **********Val Epoch 5: average Loss: 15.820843
2023-05-22 18:56: ******Current best model saved:model_para/PEMS03/epoch_5.pth!
2023-05-22 18:56: Train Epoch 6: 0/490 Loss: 15.720205
2023-05-22 18:56: Train Epoch 6: 20/490 Loss: 15.487020
2023-05-22 18:56: Train Epoch 6: 40/490 Loss: 15.108159
2023-05-22 18:57: Train Epoch 6: 60/490 Loss: 18.219633
2023-05-22 18:57: Train Epoch 6: 80/490 Loss: 13.469881
2023-05-22 18:57: Train Epoch 6: 100/490 Loss: 17.714283
2023-05-22 18:57: Train Epoch 6: 120/490 Loss: 14.792833
2023-05-22 18:57: Train Epoch 6: 140/490 Loss: 15.181185
2023-05-22 18:57: Train Epoch 6: 160/490 Loss: 17.731775
2023-05-22 18:57: Train Epoch 6: 180/490 Loss: 16.231670
2023-05-22 18:57: Train Epoch 6: 200/490 Loss: 14.574247
2023-05-22 18:57: Train Epoch 6: 220/490 Loss: 15.285956
2023-05-22 18:57: Train Epoch 6: 240/490 Loss: 13.665628
2023-05-22 18:57: Train Epoch 6: 260/490 Loss: 14.994654
2023-05-22 18:57: Train Epoch 6: 280/490 Loss: 16.269394
2023-05-22 18:57: Train Epoch 6: 300/490 Loss: 16.585453
2023-05-22 18:57: Train Epoch 6: 320/490 Loss: 15.502346
2023-05-22 18:58: Train Epoch 6: 340/490 Loss: 13.911582
2023-05-22 18:58: Train Epoch 6: 360/490 Loss: 15.636990
2023-05-22 18:58: Train Epoch 6: 380/490 Loss: 14.704039
2023-05-22 18:58: Train Epoch 6: 400/490 Loss: 15.771625
2023-05-22 18:58: Train Epoch 6: 420/490 Loss: 15.283590
2023-05-22 18:58: Train Epoch 6: 440/490 Loss: 14.893783
2023-05-22 18:58: Train Epoch 6: 460/490 Loss: 15.398750
2023-05-22 18:58: Train Epoch 6: 480/490 Loss: 16.046667
2023-05-22 18:58: **********Train Epoch 6: averaged Loss: 15.455382, tf_ratio: 1.000000
2023-05-22 18:58: **********Val Epoch 6: average Loss: 15.797796
2023-05-22 18:58: ******Current best model saved:model_para/PEMS03/epoch_6.pth!
2023-05-22 18:58: Train Epoch 7: 0/490 Loss: 16.331285
2023-05-22 18:58: Train Epoch 7: 20/490 Loss: 15.529264
2023-05-22 18:58: Train Epoch 7: 40/490 Loss: 16.215487
2023-05-22 18:58: Train Epoch 7: 60/490 Loss: 16.139620
2023-05-22 18:59: Train Epoch 7: 80/490 Loss: 14.862056
2023-05-22 18:59: Train Epoch 7: 100/490 Loss: 15.844251
2023-05-22 18:59: Train Epoch 7: 120/490 Loss: 14.780704
2023-05-22 18:59: Train Epoch 7: 140/490 Loss: 14.986095
2023-05-22 18:59: Train Epoch 7: 160/490 Loss: 14.981274
2023-05-22 18:59: Train Epoch 7: 180/490 Loss: 13.384528
2023-05-22 18:59: Train Epoch 7: 200/490 Loss: 14.863131
2023-05-22 18:59: Train Epoch 7: 220/490 Loss: 15.557859
2023-05-22 18:59: Train Epoch 7: 240/490 Loss: 15.095630
2023-05-22 18:59: Train Epoch 7: 260/490 Loss: 13.633947
2023-05-22 18:59: Train Epoch 7: 280/490 Loss: 15.654335
2023-05-22 18:59: Train Epoch 7: 300/490 Loss: 14.140121
2023-05-22 18:59: Train Epoch 7: 320/490 Loss: 15.946030
2023-05-22 18:59: Train Epoch 7: 340/490 Loss: 16.031122
2023-05-22 19:00: Train Epoch 7: 360/490 Loss: 13.550094
2023-05-22 19:00: Train Epoch 7: 380/490 Loss: 15.062953
2023-05-22 19:00: Train Epoch 7: 400/490 Loss: 15.095469
2023-05-22 19:00: Train Epoch 7: 420/490 Loss: 16.148773
2023-05-22 19:00: Train Epoch 7: 440/490 Loss: 13.660820
2023-05-22 19:00: Train Epoch 7: 460/490 Loss: 15.882796
2023-05-22 19:00: Train Epoch 7: 480/490 Loss: 16.950401
2023-05-22 19:00: **********Train Epoch 7: averaged Loss: 15.243898, tf_ratio: 1.000000
2023-05-22 19:00: **********Val Epoch 7: average Loss: 15.520705
2023-05-22 19:00: ******Current best model saved:model_para/PEMS03/epoch_7.pth!
2023-05-22 19:00: Train Epoch 8: 0/490 Loss: 14.081936
2023-05-22 19:00: Train Epoch 8: 20/490 Loss: 13.306451
2023-05-22 19:00: Train Epoch 8: 40/490 Loss: 16.521320
2023-05-22 19:00: Train Epoch 8: 60/490 Loss: 14.344463
2023-05-22 19:00: Train Epoch 8: 80/490 Loss: 14.624670
2023-05-22 19:01: Train Epoch 8: 100/490 Loss: 14.710882
2023-05-22 19:01: Train Epoch 8: 120/490 Loss: 15.298573
2023-05-22 19:01: Train Epoch 8: 140/490 Loss: 15.864196
2023-05-22 19:01: Train Epoch 8: 160/490 Loss: 14.122595
2023-05-22 19:01: Train Epoch 8: 180/490 Loss: 15.614103
2023-05-22 19:01: Train Epoch 8: 200/490 Loss: 14.886281
2023-05-22 19:01: Train Epoch 8: 220/490 Loss: 13.100387
2023-05-22 19:01: Train Epoch 8: 240/490 Loss: 16.541592
2023-05-22 19:01: Train Epoch 8: 260/490 Loss: 15.186149
2023-05-22 19:01: Train Epoch 8: 280/490 Loss: 17.407187
2023-05-22 19:01: Train Epoch 8: 300/490 Loss: 13.167314
2023-05-22 19:01: Train Epoch 8: 320/490 Loss: 14.618671
2023-05-22 19:01: Train Epoch 8: 340/490 Loss: 14.876734
2023-05-22 19:01: Train Epoch 8: 360/490 Loss: 16.405363
2023-05-22 19:02: Train Epoch 8: 380/490 Loss: 16.062149
2023-05-22 19:02: Train Epoch 8: 400/490 Loss: 15.209666
2023-05-22 19:02: Train Epoch 8: 420/490 Loss: 16.558338
2023-05-22 19:02: Train Epoch 8: 440/490 Loss: 14.997487
2023-05-22 19:02: Train Epoch 8: 460/490 Loss: 13.637506
2023-05-22 19:02: Train Epoch 8: 480/490 Loss: 14.556858
2023-05-22 19:02: **********Train Epoch 8: averaged Loss: 15.044261, tf_ratio: 1.000000
2023-05-22 19:02: **********Val Epoch 8: average Loss: 15.408485
2023-05-22 19:02: ******Current best model saved:model_para/PEMS03/epoch_8.pth!
2023-05-22 19:02: Train Epoch 9: 0/490 Loss: 13.211048
2023-05-22 19:02: Train Epoch 9: 20/490 Loss: 14.610608
2023-05-22 19:02: Train Epoch 9: 40/490 Loss: 15.420140
2023-05-22 19:02: Train Epoch 9: 60/490 Loss: 14.606202
2023-05-22 19:02: Train Epoch 9: 80/490 Loss: 15.628986
2023-05-22 19:02: Train Epoch 9: 100/490 Loss: 17.176308
2023-05-22 19:03: Train Epoch 9: 120/490 Loss: 16.147558
2023-05-22 19:03: Train Epoch 9: 140/490 Loss: 14.119810
2023-05-22 19:03: Train Epoch 9: 160/490 Loss: 14.829004
2023-05-22 19:03: Train Epoch 9: 180/490 Loss: 14.378408
2023-05-22 19:03: Train Epoch 9: 200/490 Loss: 15.727198
2023-05-22 19:03: Train Epoch 9: 220/490 Loss: 14.716513
2023-05-22 19:03: Train Epoch 9: 240/490 Loss: 16.606310
2023-05-22 19:03: Train Epoch 9: 260/490 Loss: 14.742333
2023-05-22 19:03: Train Epoch 9: 280/490 Loss: 16.289963
2023-05-22 19:03: Train Epoch 9: 300/490 Loss: 15.421137
2023-05-22 19:03: Train Epoch 9: 320/490 Loss: 15.801214
2023-05-22 19:03: Train Epoch 9: 340/490 Loss: 14.499488
2023-05-22 19:03: Train Epoch 9: 360/490 Loss: 13.428379
2023-05-22 19:03: Train Epoch 9: 380/490 Loss: 14.566498
2023-05-22 19:04: Train Epoch 9: 400/490 Loss: 13.247439
2023-05-22 19:04: Train Epoch 9: 420/490 Loss: 15.462933
2023-05-22 19:04: Train Epoch 9: 440/490 Loss: 15.645112
2023-05-22 19:04: Train Epoch 9: 460/490 Loss: 14.937154
2023-05-22 19:04: Train Epoch 9: 480/490 Loss: 13.879119
2023-05-22 19:04: **********Train Epoch 9: averaged Loss: 14.818885, tf_ratio: 1.000000
2023-05-22 19:04: **********Val Epoch 9: average Loss: 15.417414
2023-05-22 19:04: Train Epoch 10: 0/490 Loss: 15.492863
2023-05-22 19:04: Train Epoch 10: 20/490 Loss: 15.173256
2023-05-22 19:04: Train Epoch 10: 40/490 Loss: 14.878520
2023-05-22 19:04: Train Epoch 10: 60/490 Loss: 15.634250
2023-05-22 19:04: Train Epoch 10: 80/490 Loss: 15.014318
2023-05-22 19:04: Train Epoch 10: 100/490 Loss: 15.511899
2023-05-22 19:04: Train Epoch 10: 120/490 Loss: 14.690489
2023-05-22 19:05: Train Epoch 10: 140/490 Loss: 14.595992
2023-05-22 19:05: Train Epoch 10: 160/490 Loss: 15.042357
2023-05-22 19:05: Train Epoch 10: 180/490 Loss: 15.152740
2023-05-22 19:05: Train Epoch 10: 200/490 Loss: 14.158158
2023-05-22 19:05: Train Epoch 10: 220/490 Loss: 14.745274
2023-05-22 19:05: Train Epoch 10: 240/490 Loss: 15.704988
2023-05-22 19:05: Train Epoch 10: 260/490 Loss: 13.604349
2023-05-22 19:05: Train Epoch 10: 280/490 Loss: 14.100183
2023-05-22 19:05: Train Epoch 10: 300/490 Loss: 14.300205
2023-05-22 19:05: Train Epoch 10: 320/490 Loss: 14.354407
2023-05-22 19:05: Train Epoch 10: 340/490 Loss: 16.064154
2023-05-22 19:05: Train Epoch 10: 360/490 Loss: 14.489231
2023-05-22 19:05: Train Epoch 10: 380/490 Loss: 14.391923
2023-05-22 19:05: Train Epoch 10: 400/490 Loss: 13.983216
2023-05-22 19:06: Train Epoch 10: 420/490 Loss: 14.537915
2023-05-22 19:06: Train Epoch 10: 440/490 Loss: 15.415952
2023-05-22 19:06: Train Epoch 10: 460/490 Loss: 14.796803
2023-05-22 19:06: Train Epoch 10: 480/490 Loss: 15.132933
2023-05-22 19:06: **********Train Epoch 10: averaged Loss: 14.673593, tf_ratio: 1.000000
2023-05-22 19:06: **********Val Epoch 10: average Loss: 15.142346
2023-05-22 19:06: ******Current best model saved:model_para/PEMS03/epoch_10.pth!
2023-05-22 19:06: Train Epoch 11: 0/490 Loss: 13.794102
2023-05-22 19:06: Train Epoch 11: 20/490 Loss: 15.537677
2023-05-22 19:06: Train Epoch 11: 40/490 Loss: 15.828091
2023-05-22 19:06: Train Epoch 11: 60/490 Loss: 14.569301
2023-05-22 19:06: Train Epoch 11: 80/490 Loss: 13.643355
2023-05-22 19:06: Train Epoch 11: 100/490 Loss: 15.877352
2023-05-22 19:06: Train Epoch 11: 120/490 Loss: 15.822536
2023-05-22 19:06: Train Epoch 11: 140/490 Loss: 14.823336
2023-05-22 19:07: Train Epoch 11: 160/490 Loss: 14.514579
2023-05-22 19:07: Train Epoch 11: 180/490 Loss: 14.778881
2023-05-22 19:07: Train Epoch 11: 200/490 Loss: 14.252448
2023-05-22 19:07: Train Epoch 11: 220/490 Loss: 13.845997
2023-05-22 19:07: Train Epoch 11: 240/490 Loss: 15.241851
2023-05-22 19:07: Train Epoch 11: 260/490 Loss: 14.805913
2023-05-22 19:07: Train Epoch 11: 280/490 Loss: 14.812076
2023-05-22 19:07: Train Epoch 11: 300/490 Loss: 14.313533
2023-05-22 19:07: Train Epoch 11: 320/490 Loss: 13.336423
2023-05-22 19:07: Train Epoch 11: 340/490 Loss: 15.088838
2023-05-22 19:07: Train Epoch 11: 360/490 Loss: 15.319982
2023-05-22 19:07: Train Epoch 11: 380/490 Loss: 13.871963
2023-05-22 19:07: Train Epoch 11: 400/490 Loss: 14.321666
2023-05-22 19:07: Train Epoch 11: 420/490 Loss: 14.661947
2023-05-22 19:08: Train Epoch 11: 440/490 Loss: 14.241698
2023-05-22 19:08: Train Epoch 11: 460/490 Loss: 13.383168
2023-05-22 19:08: Train Epoch 11: 480/490 Loss: 14.010825
2023-05-22 19:08: **********Train Epoch 11: averaged Loss: 14.595437, tf_ratio: 1.000000
2023-05-22 19:08: **********Val Epoch 11: average Loss: 15.602231
2023-05-22 19:08: Train Epoch 12: 0/490 Loss: 15.529281
2023-05-22 19:08: Train Epoch 12: 20/490 Loss: 14.512772
2023-05-22 19:08: Train Epoch 12: 40/490 Loss: 13.082737
2023-05-22 19:08: Train Epoch 12: 60/490 Loss: 12.742314
2023-05-22 19:08: Train Epoch 12: 80/490 Loss: 13.579110
2023-05-22 19:08: Train Epoch 12: 100/490 Loss: 12.837914
2023-05-22 19:08: Train Epoch 12: 120/490 Loss: 14.971383
2023-05-22 19:08: Train Epoch 12: 140/490 Loss: 13.946706
2023-05-22 19:09: Train Epoch 12: 160/490 Loss: 15.077274
2023-05-22 19:09: Train Epoch 12: 180/490 Loss: 14.531869
2023-05-22 19:09: Train Epoch 12: 200/490 Loss: 12.973367
2023-05-22 19:09: Train Epoch 12: 220/490 Loss: 15.775124
2023-05-22 19:09: Train Epoch 12: 240/490 Loss: 13.345467
2023-05-22 19:09: Train Epoch 12: 260/490 Loss: 13.256487
2023-05-22 19:09: Train Epoch 12: 280/490 Loss: 12.580758
2023-05-22 19:09: Train Epoch 12: 300/490 Loss: 13.958860
2023-05-22 19:09: Train Epoch 12: 320/490 Loss: 15.531719
2023-05-22 19:09: Train Epoch 12: 340/490 Loss: 15.161919
2023-05-22 19:09: Train Epoch 12: 360/490 Loss: 14.507533
2023-05-22 19:09: Train Epoch 12: 380/490 Loss: 15.788643
2023-05-22 19:09: Train Epoch 12: 400/490 Loss: 13.429203
2023-05-22 19:09: Train Epoch 12: 420/490 Loss: 13.107201
2023-05-22 19:09: Train Epoch 12: 440/490 Loss: 13.782475
2023-05-22 19:10: Train Epoch 12: 460/490 Loss: 15.334965
2023-05-22 19:10: Train Epoch 12: 480/490 Loss: 14.674088
2023-05-22 19:10: **********Train Epoch 12: averaged Loss: 14.426540, tf_ratio: 1.000000
2023-05-22 19:10: **********Val Epoch 12: average Loss: 14.915463
2023-05-22 19:10: ******Current best model saved:model_para/PEMS03/epoch_12.pth!
2023-05-22 19:10: Train Epoch 13: 0/490 Loss: 13.304371
2023-05-22 19:10: Train Epoch 13: 20/490 Loss: 13.698239
2023-05-22 19:10: Train Epoch 13: 40/490 Loss: 13.135713
2023-05-22 19:10: Train Epoch 13: 60/490 Loss: 13.269138
2023-05-22 19:10: Train Epoch 13: 80/490 Loss: 14.515235
2023-05-22 19:10: Train Epoch 13: 100/490 Loss: 12.887025
2023-05-22 19:10: Train Epoch 13: 120/490 Loss: 14.227814
2023-05-22 19:10: Train Epoch 13: 140/490 Loss: 12.945025
2023-05-22 19:10: Train Epoch 13: 160/490 Loss: 12.078432
2023-05-22 19:11: Train Epoch 13: 180/490 Loss: 14.681837
2023-05-22 19:11: Train Epoch 13: 200/490 Loss: 15.513778
2023-05-22 19:11: Train Epoch 13: 220/490 Loss: 14.139314
2023-05-22 19:11: Train Epoch 13: 240/490 Loss: 15.944798
2023-05-22 19:11: Train Epoch 13: 260/490 Loss: 13.462792
2023-05-22 19:11: Train Epoch 13: 280/490 Loss: 13.648288
2023-05-22 19:11: Train Epoch 13: 300/490 Loss: 14.959277
2023-05-22 19:11: Train Epoch 13: 320/490 Loss: 14.356140
2023-05-22 19:11: Train Epoch 13: 340/490 Loss: 13.117438
2023-05-22 19:11: Train Epoch 13: 360/490 Loss: 13.463265
2023-05-22 19:11: Train Epoch 13: 380/490 Loss: 14.051606
2023-05-22 19:11: Train Epoch 13: 400/490 Loss: 14.187809
2023-05-22 19:11: Train Epoch 13: 420/490 Loss: 14.106442
2023-05-22 19:11: Train Epoch 13: 440/490 Loss: 14.950681
2023-05-22 19:12: Train Epoch 13: 460/490 Loss: 14.726598
2023-05-22 19:12: Train Epoch 13: 480/490 Loss: 14.443487
2023-05-22 19:12: **********Train Epoch 13: averaged Loss: 14.284376, tf_ratio: 1.000000
2023-05-22 19:12: **********Val Epoch 13: average Loss: 14.782635
2023-05-22 19:12: ******Current best model saved:model_para/PEMS03/epoch_13.pth!
2023-05-22 19:12: Train Epoch 14: 0/490 Loss: 15.367204
2023-05-22 19:12: Train Epoch 14: 20/490 Loss: 14.927713
2023-05-22 19:12: Train Epoch 14: 40/490 Loss: 12.718134
2023-05-22 19:12: Train Epoch 14: 60/490 Loss: 13.713510
2023-05-22 19:12: Train Epoch 14: 80/490 Loss: 13.678107
2023-05-22 19:12: Train Epoch 14: 100/490 Loss: 14.509633
2023-05-22 19:12: Train Epoch 14: 120/490 Loss: 15.115378
2023-05-22 19:12: Train Epoch 14: 140/490 Loss: 15.188172
2023-05-22 19:12: Train Epoch 14: 160/490 Loss: 14.184296
2023-05-22 19:12: Train Epoch 14: 180/490 Loss: 15.282321
2023-05-22 19:13: Train Epoch 14: 200/490 Loss: 14.537908
2023-05-22 19:13: Train Epoch 14: 220/490 Loss: 15.043784
2023-05-22 19:13: Train Epoch 14: 240/490 Loss: 14.335875
2023-05-22 19:13: Train Epoch 14: 260/490 Loss: 12.928822
2023-05-22 19:13: Train Epoch 14: 280/490 Loss: 14.829286
2023-05-22 19:13: Train Epoch 14: 300/490 Loss: 14.665596
2023-05-22 19:13: Train Epoch 14: 320/490 Loss: 14.032893
2023-05-22 19:13: Train Epoch 14: 340/490 Loss: 13.575337
2023-05-22 19:13: Train Epoch 14: 360/490 Loss: 12.372356
2023-05-22 19:13: Train Epoch 14: 380/490 Loss: 13.488796
2023-05-22 19:13: Train Epoch 14: 400/490 Loss: 14.170153
2023-05-22 19:13: Train Epoch 14: 420/490 Loss: 13.522047
2023-05-22 19:13: Train Epoch 14: 440/490 Loss: 15.463402
2023-05-22 19:13: Train Epoch 14: 460/490 Loss: 14.218887
2023-05-22 19:14: Train Epoch 14: 480/490 Loss: 14.495389
2023-05-22 19:14: **********Train Epoch 14: averaged Loss: 14.183511, tf_ratio: 1.000000
2023-05-22 19:14: **********Val Epoch 14: average Loss: 15.051910
2023-05-22 19:14: Train Epoch 15: 0/490 Loss: 14.901361
2023-05-22 19:14: Train Epoch 15: 20/490 Loss: 14.159666
2023-05-22 19:14: Train Epoch 15: 40/490 Loss: 15.649121
2023-05-22 19:14: Train Epoch 15: 60/490 Loss: 14.332539
2023-05-22 19:14: Train Epoch 15: 80/490 Loss: 13.754862
2023-05-22 19:14: Train Epoch 15: 100/490 Loss: 13.789459
2023-05-22 19:14: Train Epoch 15: 120/490 Loss: 13.781611
2023-05-22 19:14: Train Epoch 15: 140/490 Loss: 14.398350
2023-05-22 19:14: Train Epoch 15: 160/490 Loss: 13.500857
2023-05-22 19:14: Train Epoch 15: 180/490 Loss: 14.228920
2023-05-22 19:14: Train Epoch 15: 200/490 Loss: 12.310013
2023-05-22 19:15: Train Epoch 15: 220/490 Loss: 14.034310
2023-05-22 19:15: Train Epoch 15: 240/490 Loss: 13.180829
2023-05-22 19:15: Train Epoch 15: 260/490 Loss: 13.225945
2023-05-22 19:15: Train Epoch 15: 280/490 Loss: 13.686079
2023-05-22 19:15: Train Epoch 15: 300/490 Loss: 14.155083
2023-05-22 19:15: Train Epoch 15: 320/490 Loss: 14.446463
2023-05-22 19:15: Train Epoch 15: 340/490 Loss: 14.159514
2023-05-22 19:15: Train Epoch 15: 360/490 Loss: 14.918129
2023-05-22 19:15: Train Epoch 15: 380/490 Loss: 14.688502
2023-05-22 19:15: Train Epoch 15: 400/490 Loss: 13.776977
2023-05-22 19:15: Train Epoch 15: 420/490 Loss: 12.556747
2023-05-22 19:15: Train Epoch 15: 440/490 Loss: 13.095014
2023-05-22 19:15: Train Epoch 15: 460/490 Loss: 13.352920
2023-05-22 19:15: Train Epoch 15: 480/490 Loss: 15.097214
2023-05-22 19:15: **********Train Epoch 15: averaged Loss: 14.088699, tf_ratio: 1.000000
2023-05-22 19:16: **********Val Epoch 15: average Loss: 14.775081
2023-05-22 19:16: ******Current best model saved:model_para/PEMS03/epoch_15.pth!
2023-05-22 19:16: Train Epoch 16: 0/490 Loss: 13.923568
2023-05-22 19:16: Train Epoch 16: 20/490 Loss: 15.203362
2023-05-22 19:16: Train Epoch 16: 40/490 Loss: 14.796417
2023-05-22 19:16: Train Epoch 16: 60/490 Loss: 14.351805
2023-05-22 19:16: Train Epoch 16: 80/490 Loss: 13.929835
2023-05-22 19:16: Train Epoch 16: 100/490 Loss: 13.378184
2023-05-22 19:16: Train Epoch 16: 120/490 Loss: 15.219766
2023-05-22 19:16: Train Epoch 16: 140/490 Loss: 13.030407
2023-05-22 19:16: Train Epoch 16: 160/490 Loss: 14.141417
2023-05-22 19:16: Train Epoch 16: 180/490 Loss: 13.076078
2023-05-22 19:16: Train Epoch 16: 200/490 Loss: 14.136182
2023-05-22 19:16: Train Epoch 16: 220/490 Loss: 14.568224
2023-05-22 19:17: Train Epoch 16: 240/490 Loss: 12.734712
2023-05-22 19:17: Train Epoch 16: 260/490 Loss: 12.748112
2023-05-22 19:17: Train Epoch 16: 280/490 Loss: 13.699286
2023-05-22 19:17: Train Epoch 16: 300/490 Loss: 11.376409
2023-05-22 19:17: Train Epoch 16: 320/490 Loss: 14.779994
2023-05-22 19:17: Train Epoch 16: 340/490 Loss: 14.123512
2023-05-22 19:17: Train Epoch 16: 360/490 Loss: 14.042200
2023-05-22 19:17: Train Epoch 16: 380/490 Loss: 13.117064
2023-05-22 19:17: Train Epoch 16: 400/490 Loss: 14.844425
2023-05-22 19:17: Train Epoch 16: 420/490 Loss: 14.760672
2023-05-22 19:17: Train Epoch 16: 440/490 Loss: 13.289415
2023-05-22 19:17: Train Epoch 16: 460/490 Loss: 15.060209
2023-05-22 19:17: Train Epoch 16: 480/490 Loss: 14.988846
2023-05-22 19:17: **********Train Epoch 16: averaged Loss: 14.059125, tf_ratio: 1.000000
2023-05-22 19:18: **********Val Epoch 16: average Loss: 14.764588
2023-05-22 19:18: ******Current best model saved:model_para/PEMS03/epoch_16.pth!
2023-05-22 19:18: Train Epoch 17: 0/490 Loss: 12.335036
2023-05-22 19:18: Train Epoch 17: 20/490 Loss: 13.937549
2023-05-22 19:18: Train Epoch 17: 40/490 Loss: 14.618210
2023-05-22 19:18: Train Epoch 17: 60/490 Loss: 12.491898
2023-05-22 19:18: Train Epoch 17: 80/490 Loss: 15.527164
2023-05-22 19:18: Train Epoch 17: 100/490 Loss: 13.320415
2023-05-22 19:18: Train Epoch 17: 120/490 Loss: 13.512695
2023-05-22 19:18: Train Epoch 17: 140/490 Loss: 15.259855
2023-05-22 19:18: Train Epoch 17: 160/490 Loss: 14.243753
2023-05-22 19:18: Train Epoch 17: 180/490 Loss: 14.825150
2023-05-22 19:18: Train Epoch 17: 200/490 Loss: 14.866622
2023-05-22 19:18: Train Epoch 17: 220/490 Loss: 13.010571
2023-05-22 19:18: Train Epoch 17: 240/490 Loss: 14.498431
2023-05-22 19:19: Train Epoch 17: 260/490 Loss: 13.540060
2023-05-22 19:19: Train Epoch 17: 280/490 Loss: 15.546672
2023-05-22 19:19: Train Epoch 17: 300/490 Loss: 13.762142
2023-05-22 19:19: Train Epoch 17: 320/490 Loss: 13.432982
2023-05-22 19:19: Train Epoch 17: 340/490 Loss: 12.735565
2023-05-22 19:19: Train Epoch 17: 360/490 Loss: 13.666308
2023-05-22 19:19: Train Epoch 17: 380/490 Loss: 13.611884
2023-05-22 19:19: Train Epoch 17: 400/490 Loss: 12.912807
2023-05-22 19:19: Train Epoch 17: 420/490 Loss: 14.664658
2023-05-22 19:19: Train Epoch 17: 440/490 Loss: 12.964158
2023-05-22 19:19: Train Epoch 17: 460/490 Loss: 13.983594
2023-05-22 19:19: Train Epoch 17: 480/490 Loss: 15.426030
2023-05-22 19:19: **********Train Epoch 17: averaged Loss: 13.920458, tf_ratio: 1.000000
2023-05-22 19:20: **********Val Epoch 17: average Loss: 14.646993
2023-05-22 19:20: ******Current best model saved:model_para/PEMS03/epoch_17.pth!
2023-05-22 19:20: Train Epoch 18: 0/490 Loss: 14.869430
2023-05-22 19:20: Train Epoch 18: 20/490 Loss: 15.363243
2023-05-22 19:20: Train Epoch 18: 40/490 Loss: 12.971196
2023-05-22 19:20: Train Epoch 18: 60/490 Loss: 15.039696
2023-05-22 19:20: Train Epoch 18: 80/490 Loss: 12.788157
2023-05-22 19:20: Train Epoch 18: 100/490 Loss: 13.448958
2023-05-22 19:20: Train Epoch 18: 120/490 Loss: 13.693401
2023-05-22 19:20: Train Epoch 18: 140/490 Loss: 13.981775
2023-05-22 19:20: Train Epoch 18: 160/490 Loss: 13.712864
2023-05-22 19:20: Train Epoch 18: 180/490 Loss: 12.468743
2023-05-22 19:20: Train Epoch 18: 200/490 Loss: 13.731321
2023-05-22 19:20: Train Epoch 18: 220/490 Loss: 13.779034
2023-05-22 19:20: Train Epoch 18: 240/490 Loss: 13.392098
2023-05-22 19:20: Train Epoch 18: 260/490 Loss: 13.738820
2023-05-22 19:21: Train Epoch 18: 280/490 Loss: 15.613913
2023-05-22 19:21: Train Epoch 18: 300/490 Loss: 13.324110
2023-05-22 19:21: Train Epoch 18: 320/490 Loss: 13.328614
2023-05-22 19:21: Train Epoch 18: 340/490 Loss: 12.963844
2023-05-22 19:21: Train Epoch 18: 360/490 Loss: 13.577316
2023-05-22 19:21: Train Epoch 18: 380/490 Loss: 14.017466
2023-05-22 19:21: Train Epoch 18: 400/490 Loss: 13.217787
2023-05-22 19:21: Train Epoch 18: 420/490 Loss: 13.341510
2023-05-22 19:21: Train Epoch 18: 440/490 Loss: 13.182638
2023-05-22 19:21: Train Epoch 18: 460/490 Loss: 13.227875
2023-05-22 19:21: Train Epoch 18: 480/490 Loss: 14.836653
2023-05-22 19:21: **********Train Epoch 18: averaged Loss: 13.872676, tf_ratio: 1.000000
2023-05-22 19:21: **********Val Epoch 18: average Loss: 14.691317
2023-05-22 19:21: Train Epoch 19: 0/490 Loss: 13.150521
2023-05-22 19:22: Train Epoch 19: 20/490 Loss: 12.225375
2023-05-22 19:22: Train Epoch 19: 40/490 Loss: 13.917221
2023-05-22 19:22: Train Epoch 19: 60/490 Loss: 11.389466
2023-05-22 19:22: Train Epoch 19: 80/490 Loss: 13.272531
2023-05-22 19:22: Train Epoch 19: 100/490 Loss: 12.754855
2023-05-22 19:22: Train Epoch 19: 120/490 Loss: 13.328089
2023-05-22 19:22: Train Epoch 19: 140/490 Loss: 14.259962
2023-05-22 19:22: Train Epoch 19: 160/490 Loss: 13.182923
2023-05-22 19:22: Train Epoch 19: 180/490 Loss: 13.851838
2023-05-22 19:22: Train Epoch 19: 200/490 Loss: 13.981410
2023-05-22 19:22: Train Epoch 19: 220/490 Loss: 13.806418
2023-05-22 19:22: Train Epoch 19: 240/490 Loss: 13.211191
2023-05-22 19:22: Train Epoch 19: 260/490 Loss: 13.844662
2023-05-22 19:22: Train Epoch 19: 280/490 Loss: 13.999970
2023-05-22 19:23: Train Epoch 19: 300/490 Loss: 12.934435
2023-05-22 19:23: Train Epoch 19: 320/490 Loss: 13.442574
2023-05-22 19:23: Train Epoch 19: 340/490 Loss: 14.276310
2023-05-22 19:23: Train Epoch 19: 360/490 Loss: 13.858997
2023-05-22 19:23: Train Epoch 19: 380/490 Loss: 15.064798
2023-05-22 19:23: Train Epoch 19: 400/490 Loss: 14.557846
2023-05-22 19:23: Train Epoch 19: 420/490 Loss: 14.003537
2023-05-22 19:23: Train Epoch 19: 440/490 Loss: 13.348646
2023-05-22 19:23: Train Epoch 19: 460/490 Loss: 13.430841
2023-05-22 19:23: Train Epoch 19: 480/490 Loss: 15.313975
2023-05-22 19:23: **********Train Epoch 19: averaged Loss: 13.786613, tf_ratio: 1.000000
2023-05-22 19:23: **********Val Epoch 19: average Loss: 14.598565
2023-05-22 19:23: ******Current best model saved:model_para/PEMS03/epoch_19.pth!
2023-05-22 19:23: Train Epoch 20: 0/490 Loss: 13.443897
2023-05-22 19:23: Train Epoch 20: 20/490 Loss: 13.099824
2023-05-22 19:24: Train Epoch 20: 40/490 Loss: 14.067339
2023-05-22 19:24: Train Epoch 20: 60/490 Loss: 13.164895
2023-05-22 19:24: Train Epoch 20: 80/490 Loss: 14.581043
2023-05-22 19:24: Train Epoch 20: 100/490 Loss: 14.939898
2023-05-22 19:24: Train Epoch 20: 120/490 Loss: 13.253748
2023-05-22 19:24: Train Epoch 20: 140/490 Loss: 12.959973
2023-05-22 19:24: Train Epoch 20: 160/490 Loss: 12.560717
2023-05-22 19:24: Train Epoch 20: 180/490 Loss: 13.178282
2023-05-22 19:24: Train Epoch 20: 200/490 Loss: 13.515660
2023-05-22 19:24: Train Epoch 20: 220/490 Loss: 12.930654
2023-05-22 19:24: Train Epoch 20: 240/490 Loss: 13.535768
2023-05-22 19:24: Train Epoch 20: 260/490 Loss: 13.805442
2023-05-22 19:24: Train Epoch 20: 280/490 Loss: 13.183690
2023-05-22 19:24: Train Epoch 20: 300/490 Loss: 14.335422
2023-05-22 19:25: Train Epoch 20: 320/490 Loss: 11.948542
2023-05-22 19:25: Train Epoch 20: 340/490 Loss: 15.022255
2023-05-22 19:25: Train Epoch 20: 360/490 Loss: 14.332734
2023-05-22 19:25: Train Epoch 20: 380/490 Loss: 12.116861
2023-05-22 19:25: Train Epoch 20: 400/490 Loss: 13.766186
2023-05-22 19:25: Train Epoch 20: 420/490 Loss: 14.166500
2023-05-22 19:25: Train Epoch 20: 440/490 Loss: 14.057587
2023-05-22 19:25: Train Epoch 20: 460/490 Loss: 13.235293
2023-05-22 19:25: Train Epoch 20: 480/490 Loss: 12.576852
2023-05-22 19:25: **********Train Epoch 20: averaged Loss: 13.708137, tf_ratio: 1.000000
2023-05-22 19:25: **********Val Epoch 20: average Loss: 14.470140
2023-05-22 19:25: ******Current best model saved:model_para/PEMS03/epoch_20.pth!
2023-05-22 19:25: Train Epoch 21: 0/490 Loss: 12.423520
2023-05-22 19:25: Train Epoch 21: 20/490 Loss: 12.055566
2023-05-22 19:26: Train Epoch 21: 40/490 Loss: 13.779184
2023-05-22 19:26: Train Epoch 21: 60/490 Loss: 14.472529
2023-05-22 19:26: Train Epoch 21: 80/490 Loss: 14.591948
2023-05-22 19:26: Train Epoch 21: 100/490 Loss: 13.113058
2023-05-22 19:26: Train Epoch 21: 120/490 Loss: 14.259568
2023-05-22 19:26: Train Epoch 21: 140/490 Loss: 13.445856
2023-05-22 19:26: Train Epoch 21: 160/490 Loss: 12.553023
2023-05-22 19:26: Train Epoch 21: 180/490 Loss: 12.881916
2023-05-22 19:26: Train Epoch 21: 200/490 Loss: 11.732375
2023-05-22 19:26: Train Epoch 21: 220/490 Loss: 14.893693
2023-05-22 19:26: Train Epoch 21: 240/490 Loss: 12.638080
2023-05-22 19:26: Train Epoch 21: 260/490 Loss: 12.349255
2023-05-22 19:26: Train Epoch 21: 280/490 Loss: 12.332964
2023-05-22 19:26: Train Epoch 21: 300/490 Loss: 14.866611
2023-05-22 19:27: Train Epoch 21: 320/490 Loss: 13.357636
2023-05-22 19:27: Train Epoch 21: 340/490 Loss: 12.160944
2023-05-22 19:27: Train Epoch 21: 360/490 Loss: 15.000464
2023-05-22 19:27: Train Epoch 21: 380/490 Loss: 14.424329
2023-05-22 19:27: Train Epoch 21: 400/490 Loss: 13.986214
2023-05-22 19:27: Train Epoch 21: 420/490 Loss: 14.530558
2023-05-22 19:27: Train Epoch 21: 440/490 Loss: 13.108324
2023-05-22 19:27: Train Epoch 21: 460/490 Loss: 14.666005
2023-05-22 19:27: Train Epoch 21: 480/490 Loss: 13.268819
2023-05-22 19:27: **********Train Epoch 21: averaged Loss: 13.657751, tf_ratio: 1.000000
2023-05-22 19:27: **********Val Epoch 21: average Loss: 14.503855
2023-05-22 19:27: Train Epoch 22: 0/490 Loss: 14.044676
2023-05-22 19:27: Train Epoch 22: 20/490 Loss: 13.664830
2023-05-22 19:27: Train Epoch 22: 40/490 Loss: 14.014562
2023-05-22 19:28: Train Epoch 22: 60/490 Loss: 14.544347
2023-05-22 19:28: Train Epoch 22: 80/490 Loss: 13.888777
2023-05-22 19:28: Train Epoch 22: 100/490 Loss: 12.700629
2023-05-22 19:28: Train Epoch 22: 120/490 Loss: 14.104383
2023-05-22 19:28: Train Epoch 22: 140/490 Loss: 12.925123
2023-05-22 19:28: Train Epoch 22: 160/490 Loss: 13.554235
2023-05-22 19:28: Train Epoch 22: 180/490 Loss: 13.241849
2023-05-22 19:28: Train Epoch 22: 200/490 Loss: 13.547776
2023-05-22 19:28: Train Epoch 22: 220/490 Loss: 13.744040
2023-05-22 19:28: Train Epoch 22: 240/490 Loss: 14.261607
2023-05-22 19:28: Train Epoch 22: 260/490 Loss: 13.545530
2023-05-22 19:28: Train Epoch 22: 280/490 Loss: 13.795959
2023-05-22 19:28: Train Epoch 22: 300/490 Loss: 13.479019
2023-05-22 19:28: Train Epoch 22: 320/490 Loss: 13.415141
2023-05-22 19:29: Train Epoch 22: 340/490 Loss: 13.560140
2023-05-22 19:29: Train Epoch 22: 360/490 Loss: 14.624321
2023-05-22 19:29: Train Epoch 22: 380/490 Loss: 13.088339
2023-05-22 19:29: Train Epoch 22: 400/490 Loss: 13.681616
2023-05-22 19:29: Train Epoch 22: 420/490 Loss: 14.361377
2023-05-22 19:29: Train Epoch 22: 440/490 Loss: 13.934469
2023-05-22 19:29: Train Epoch 22: 460/490 Loss: 12.907665
2023-05-22 19:29: Train Epoch 22: 480/490 Loss: 13.320420
2023-05-22 19:29: **********Train Epoch 22: averaged Loss: 13.613429, tf_ratio: 1.000000
2023-05-22 19:29: **********Val Epoch 22: average Loss: 14.523625
2023-05-22 19:29: Train Epoch 23: 0/490 Loss: 13.685587
2023-05-22 19:29: Train Epoch 23: 20/490 Loss: 12.958604
2023-05-22 19:29: Train Epoch 23: 40/490 Loss: 13.781936
2023-05-22 19:29: Train Epoch 23: 60/490 Loss: 13.273970
2023-05-22 19:30: Train Epoch 23: 80/490 Loss: 15.254065
2023-05-22 19:30: Train Epoch 23: 100/490 Loss: 13.894447
2023-05-22 19:30: Train Epoch 23: 120/490 Loss: 13.160893
2023-05-22 19:30: Train Epoch 23: 140/490 Loss: 12.955222
2023-05-22 19:30: Train Epoch 23: 160/490 Loss: 15.152840
2023-05-22 19:30: Train Epoch 23: 180/490 Loss: 14.022170
2023-05-22 19:30: Train Epoch 23: 200/490 Loss: 13.158857
2023-05-22 19:30: Train Epoch 23: 220/490 Loss: 14.306681
2023-05-22 19:30: Train Epoch 23: 240/490 Loss: 12.508159
2023-05-22 19:30: Train Epoch 23: 260/490 Loss: 11.675081
2023-05-22 19:30: Train Epoch 23: 280/490 Loss: 13.794963
2023-05-22 19:30: Train Epoch 23: 300/490 Loss: 14.504167
2023-05-22 19:30: Train Epoch 23: 320/490 Loss: 13.699474
2023-05-22 19:30: Train Epoch 23: 340/490 Loss: 14.976522
2023-05-22 19:31: Train Epoch 23: 360/490 Loss: 14.099010
2023-05-22 19:31: Train Epoch 23: 380/490 Loss: 13.343238
2023-05-22 19:31: Train Epoch 23: 400/490 Loss: 11.911187
2023-05-22 19:31: Train Epoch 23: 420/490 Loss: 12.808930
2023-05-22 19:31: Train Epoch 23: 440/490 Loss: 14.299399
2023-05-22 19:31: Train Epoch 23: 460/490 Loss: 12.801506
2023-05-22 19:31: Train Epoch 23: 480/490 Loss: 14.580935
2023-05-22 19:31: **********Train Epoch 23: averaged Loss: 13.553349, tf_ratio: 1.000000
2023-05-22 19:31: **********Val Epoch 23: average Loss: 14.546666
2023-05-22 19:31: Train Epoch 24: 0/490 Loss: 12.746509
2023-05-22 19:31: Train Epoch 24: 20/490 Loss: 14.670902
2023-05-22 19:31: Train Epoch 24: 40/490 Loss: 14.468915
2023-05-22 19:31: Train Epoch 24: 60/490 Loss: 11.590466
2023-05-22 19:31: Train Epoch 24: 80/490 Loss: 13.765104
2023-05-22 19:32: Train Epoch 24: 100/490 Loss: 13.756439
2023-05-22 19:32: Train Epoch 24: 120/490 Loss: 15.456546
2023-05-22 19:32: Train Epoch 24: 140/490 Loss: 13.702797
2023-05-22 19:32: Train Epoch 24: 160/490 Loss: 12.950150
2023-05-22 19:32: Train Epoch 24: 180/490 Loss: 13.008511
2023-05-22 19:32: Train Epoch 24: 200/490 Loss: 13.906592
2023-05-22 19:32: Train Epoch 24: 220/490 Loss: 15.235194
2023-05-22 19:32: Train Epoch 24: 240/490 Loss: 12.985939
2023-05-22 19:32: Train Epoch 24: 260/490 Loss: 13.637770
2023-05-22 19:32: Train Epoch 24: 280/490 Loss: 11.921729
2023-05-22 19:32: Train Epoch 24: 300/490 Loss: 12.441567
2023-05-22 19:32: Train Epoch 24: 320/490 Loss: 14.249893
2023-05-22 19:32: Train Epoch 24: 340/490 Loss: 12.430025
2023-05-22 19:32: Train Epoch 24: 360/490 Loss: 13.546952
2023-05-22 19:33: Train Epoch 24: 380/490 Loss: 14.325123
2023-05-22 19:33: Train Epoch 24: 400/490 Loss: 13.425303
2023-05-22 19:33: Train Epoch 24: 420/490 Loss: 12.475452
2023-05-22 19:33: Train Epoch 24: 440/490 Loss: 14.963448
2023-05-22 19:33: Train Epoch 24: 460/490 Loss: 13.025467
2023-05-22 19:33: Train Epoch 24: 480/490 Loss: 13.590687
2023-05-22 19:33: **********Train Epoch 24: averaged Loss: 13.527872, tf_ratio: 1.000000
2023-05-22 19:33: **********Val Epoch 24: average Loss: 14.460551
2023-05-22 19:33: ******Current best model saved:model_para/PEMS03/epoch_24.pth!
2023-05-22 19:33: Train Epoch 25: 0/490 Loss: 14.699167
2023-05-22 19:33: Train Epoch 25: 20/490 Loss: 12.844496
2023-05-22 19:33: Train Epoch 25: 40/490 Loss: 13.667084
2023-05-22 19:33: Train Epoch 25: 60/490 Loss: 11.613878
2023-05-22 19:33: Train Epoch 25: 80/490 Loss: 15.891520
2023-05-22 19:33: Train Epoch 25: 100/490 Loss: 11.681770
2023-05-22 19:34: Train Epoch 25: 120/490 Loss: 13.017148
2023-05-22 19:34: Train Epoch 25: 140/490 Loss: 13.748292
2023-05-22 19:34: Train Epoch 25: 160/490 Loss: 15.064121
2023-05-22 19:34: Train Epoch 25: 180/490 Loss: 11.962768
2023-05-22 19:34: Train Epoch 25: 200/490 Loss: 13.003881
2023-05-22 19:34: Train Epoch 25: 220/490 Loss: 13.848449
2023-05-22 19:34: Train Epoch 25: 240/490 Loss: 13.545814
2023-05-22 19:34: Train Epoch 25: 260/490 Loss: 15.493277
2023-05-22 19:34: Train Epoch 25: 280/490 Loss: 12.084045
2023-05-22 19:34: Train Epoch 25: 300/490 Loss: 11.756817
2023-05-22 19:34: Train Epoch 25: 320/490 Loss: 12.033354
2023-05-22 19:34: Train Epoch 25: 340/490 Loss: 13.009452
2023-05-22 19:34: Train Epoch 25: 360/490 Loss: 13.760903
2023-05-22 19:34: Train Epoch 25: 380/490 Loss: 13.858091
2023-05-22 19:35: Train Epoch 25: 400/490 Loss: 13.881258
2023-05-22 19:35: Train Epoch 25: 420/490 Loss: 13.355381
2023-05-22 19:35: Train Epoch 25: 440/490 Loss: 13.306105
2023-05-22 19:35: Train Epoch 25: 460/490 Loss: 13.464527
2023-05-22 19:35: Train Epoch 25: 480/490 Loss: 13.168116
2023-05-22 19:35: **********Train Epoch 25: averaged Loss: 13.445471, tf_ratio: 1.000000
2023-05-22 19:35: **********Val Epoch 25: average Loss: 14.495176
2023-05-22 19:35: Train Epoch 26: 0/490 Loss: 12.723873
2023-05-22 19:35: Train Epoch 26: 20/490 Loss: 14.942450
2023-05-22 19:35: Train Epoch 26: 40/490 Loss: 12.323822
2023-05-22 19:35: Train Epoch 26: 60/490 Loss: 13.352493
2023-05-22 19:35: Train Epoch 26: 80/490 Loss: 13.352698
2023-05-22 19:35: Train Epoch 26: 100/490 Loss: 13.440174
2023-05-22 19:35: Train Epoch 26: 120/490 Loss: 13.090837
2023-05-22 19:36: Train Epoch 26: 140/490 Loss: 12.431598
2023-05-22 19:36: Train Epoch 26: 160/490 Loss: 13.207757
2023-05-22 19:36: Train Epoch 26: 180/490 Loss: 13.288461
2023-05-22 19:36: Train Epoch 26: 200/490 Loss: 12.019968
2023-05-22 19:36: Train Epoch 26: 220/490 Loss: 12.480133
2023-05-22 19:36: Train Epoch 26: 240/490 Loss: 12.881361
2023-05-22 19:36: Train Epoch 26: 260/490 Loss: 13.077237
2023-05-22 19:36: Train Epoch 26: 280/490 Loss: 14.368237
2023-05-22 19:36: Train Epoch 26: 300/490 Loss: 12.461617
2023-05-22 19:36: Train Epoch 26: 320/490 Loss: 14.164712
2023-05-22 19:36: Train Epoch 26: 340/490 Loss: 14.769424
2023-05-22 19:36: Train Epoch 26: 360/490 Loss: 11.267825
2023-05-22 19:36: Train Epoch 26: 380/490 Loss: 13.185268
2023-05-22 19:36: Train Epoch 26: 400/490 Loss: 12.168653
2023-05-22 19:37: Train Epoch 26: 420/490 Loss: 14.484550
2023-05-22 19:37: Train Epoch 26: 440/490 Loss: 13.385621
2023-05-22 19:37: Train Epoch 26: 460/490 Loss: 13.234279
2023-05-22 19:37: Train Epoch 26: 480/490 Loss: 14.486866
2023-05-22 19:37: **********Train Epoch 26: averaged Loss: 13.372694, tf_ratio: 1.000000
2023-05-22 19:37: **********Val Epoch 26: average Loss: 14.381280
2023-05-22 19:37: ******Current best model saved:model_para/PEMS03/epoch_26.pth!
2023-05-22 19:37: Train Epoch 27: 0/490 Loss: 12.392416
2023-05-22 19:37: Train Epoch 27: 20/490 Loss: 13.273192
2023-05-22 19:37: Train Epoch 27: 40/490 Loss: 13.510286
2023-05-22 19:37: Train Epoch 27: 60/490 Loss: 13.610773
2023-05-22 19:37: Train Epoch 27: 80/490 Loss: 12.990827
2023-05-22 19:37: Train Epoch 27: 100/490 Loss: 14.670826
2023-05-22 19:37: Train Epoch 27: 120/490 Loss: 13.452169
2023-05-22 19:37: Train Epoch 27: 140/490 Loss: 12.779764
2023-05-22 19:38: Train Epoch 27: 160/490 Loss: 10.928662
2023-05-22 19:38: Train Epoch 27: 180/490 Loss: 13.739498
2023-05-22 19:38: Train Epoch 27: 200/490 Loss: 12.362889
2023-05-22 19:38: Train Epoch 27: 220/490 Loss: 12.951976
2023-05-22 19:38: Train Epoch 27: 240/490 Loss: 14.253361
2023-05-22 19:38: Train Epoch 27: 260/490 Loss: 12.893500
2023-05-22 19:38: Train Epoch 27: 280/490 Loss: 12.435637
2023-05-22 19:38: Train Epoch 27: 300/490 Loss: 12.964964
2023-05-22 19:38: Train Epoch 27: 320/490 Loss: 14.549134
2023-05-22 19:38: Train Epoch 27: 340/490 Loss: 13.072628
2023-05-22 19:38: Train Epoch 27: 360/490 Loss: 12.345887
2023-05-22 19:38: Train Epoch 27: 380/490 Loss: 13.271086
2023-05-22 19:38: Train Epoch 27: 400/490 Loss: 13.889528
2023-05-22 19:38: Train Epoch 27: 420/490 Loss: 14.442373
2023-05-22 19:39: Train Epoch 27: 440/490 Loss: 13.480144
2023-05-22 19:39: Train Epoch 27: 460/490 Loss: 13.777205
2023-05-22 19:39: Train Epoch 27: 480/490 Loss: 13.888341
2023-05-22 19:39: **********Train Epoch 27: averaged Loss: 13.349415, tf_ratio: 1.000000
2023-05-22 19:39: **********Val Epoch 27: average Loss: 14.341015
2023-05-22 19:39: ******Current best model saved:model_para/PEMS03/epoch_27.pth!
2023-05-22 19:39: Train Epoch 28: 0/490 Loss: 12.973595
2023-05-22 19:39: Train Epoch 28: 20/490 Loss: 14.931576
2023-05-22 19:39: Train Epoch 28: 40/490 Loss: 13.923185
2023-05-22 19:39: Train Epoch 28: 60/490 Loss: 12.322661
2023-05-22 19:39: Train Epoch 28: 80/490 Loss: 13.632056
2023-05-22 19:39: Train Epoch 28: 100/490 Loss: 14.145115
2023-05-22 19:39: Train Epoch 28: 120/490 Loss: 13.290753
2023-05-22 19:39: Train Epoch 28: 140/490 Loss: 13.703749
2023-05-22 19:39: Train Epoch 28: 160/490 Loss: 12.543777
2023-05-22 19:40: Train Epoch 28: 180/490 Loss: 12.671128
2023-05-22 19:40: Train Epoch 28: 200/490 Loss: 13.186185
2023-05-22 19:40: Train Epoch 28: 220/490 Loss: 13.593603
2023-05-22 19:40: Train Epoch 28: 240/490 Loss: 13.238414
2023-05-22 19:40: Train Epoch 28: 260/490 Loss: 11.853999
2023-05-22 19:40: Train Epoch 28: 280/490 Loss: 13.918602
2023-05-22 19:40: Train Epoch 28: 300/490 Loss: 13.221066
2023-05-22 19:40: Train Epoch 28: 320/490 Loss: 11.992270
2023-05-22 19:40: Train Epoch 28: 340/490 Loss: 12.980108
2023-05-22 19:40: Train Epoch 28: 360/490 Loss: 12.842890
2023-05-22 19:40: Train Epoch 28: 380/490 Loss: 13.111457
2023-05-22 19:40: Train Epoch 28: 400/490 Loss: 15.289054
2023-05-22 19:40: Train Epoch 28: 420/490 Loss: 14.478579
2023-05-22 19:40: Train Epoch 28: 440/490 Loss: 13.135340
2023-05-22 19:41: Train Epoch 28: 460/490 Loss: 12.742040
2023-05-22 19:41: Train Epoch 28: 480/490 Loss: 13.628539
2023-05-22 19:41: **********Train Epoch 28: averaged Loss: 13.300143, tf_ratio: 1.000000
2023-05-22 19:41: **********Val Epoch 28: average Loss: 14.294492
2023-05-22 19:41: ******Current best model saved:model_para/PEMS03/epoch_28.pth!
2023-05-22 19:41: Train Epoch 29: 0/490 Loss: 13.493338
2023-05-22 19:41: Train Epoch 29: 20/490 Loss: 13.176400
2023-05-22 19:41: Train Epoch 29: 40/490 Loss: 13.533664
2023-05-22 19:41: Train Epoch 29: 60/490 Loss: 13.615575
2023-05-22 19:41: Train Epoch 29: 80/490 Loss: 14.453365
2023-05-22 19:41: Train Epoch 29: 100/490 Loss: 13.204685
2023-05-22 19:41: Train Epoch 29: 120/490 Loss: 13.265167
2023-05-22 19:41: Train Epoch 29: 140/490 Loss: 12.525660
2023-05-22 19:41: Train Epoch 29: 160/490 Loss: 12.882142
2023-05-22 19:41: Train Epoch 29: 180/490 Loss: 12.852207
2023-05-22 19:42: Train Epoch 29: 200/490 Loss: 12.730796
2023-05-22 19:42: Train Epoch 29: 220/490 Loss: 13.404611
2023-05-22 19:42: Train Epoch 29: 240/490 Loss: 13.394254
2023-05-22 19:42: Train Epoch 29: 260/490 Loss: 12.988935
2023-05-22 19:42: Train Epoch 29: 280/490 Loss: 12.990491
2023-05-22 19:42: Train Epoch 29: 300/490 Loss: 13.649721
2023-05-22 19:42: Train Epoch 29: 320/490 Loss: 13.983499
2023-05-22 19:42: Train Epoch 29: 340/490 Loss: 13.314429
2023-05-22 19:42: Train Epoch 29: 360/490 Loss: 13.500712
2023-05-22 19:42: Train Epoch 29: 380/490 Loss: 13.801485
2023-05-22 19:42: Train Epoch 29: 400/490 Loss: 13.198486
2023-05-22 19:42: Train Epoch 29: 420/490 Loss: 13.312418
2023-05-22 19:42: Train Epoch 29: 440/490 Loss: 13.341648
2023-05-22 19:42: Train Epoch 29: 460/490 Loss: 14.773087
2023-05-22 19:43: Train Epoch 29: 480/490 Loss: 14.345145
2023-05-22 19:43: **********Train Epoch 29: averaged Loss: 13.249491, tf_ratio: 1.000000
2023-05-22 19:43: **********Val Epoch 29: average Loss: 14.336307
2023-05-22 19:43: Train Epoch 30: 0/490 Loss: 13.883635
2023-05-22 19:43: Train Epoch 30: 20/490 Loss: 11.489641
2023-05-22 19:43: Train Epoch 30: 40/490 Loss: 12.239231
2023-05-22 19:43: Train Epoch 30: 60/490 Loss: 12.272835
2023-05-22 19:43: Train Epoch 30: 80/490 Loss: 11.410335
2023-05-22 19:43: Train Epoch 30: 100/490 Loss: 12.557978
2023-05-22 19:43: Train Epoch 30: 120/490 Loss: 12.802637
2023-05-22 19:43: Train Epoch 30: 140/490 Loss: 13.659591
2023-05-22 19:43: Train Epoch 30: 160/490 Loss: 14.218952
2023-05-22 19:43: Train Epoch 30: 180/490 Loss: 11.778440
2023-05-22 19:43: Train Epoch 30: 200/490 Loss: 12.893147
2023-05-22 19:44: Train Epoch 30: 220/490 Loss: 14.455482
2023-05-22 19:44: Train Epoch 30: 240/490 Loss: 14.303390
2023-05-22 19:44: Train Epoch 30: 260/490 Loss: 12.273649
2023-05-22 19:44: Train Epoch 30: 280/490 Loss: 11.614579
2023-05-22 19:44: Train Epoch 30: 300/490 Loss: 12.802278
2023-05-22 19:44: Train Epoch 30: 320/490 Loss: 13.858900
2023-05-22 19:44: Train Epoch 30: 340/490 Loss: 11.906611
2023-05-22 19:44: Train Epoch 30: 360/490 Loss: 13.155105
2023-05-22 19:44: Train Epoch 30: 380/490 Loss: 11.728078
2023-05-22 19:44: Train Epoch 30: 400/490 Loss: 12.410980
2023-05-22 19:44: Train Epoch 30: 420/490 Loss: 12.880833
2023-05-22 19:44: Train Epoch 30: 440/490 Loss: 14.963145
2023-05-22 19:44: Train Epoch 30: 460/490 Loss: 13.248807
2023-05-22 19:44: Train Epoch 30: 480/490 Loss: 11.820757
2023-05-22 19:44: **********Train Epoch 30: averaged Loss: 13.216307, tf_ratio: 1.000000
2023-05-22 19:45: **********Val Epoch 30: average Loss: 14.225003
2023-05-22 19:45: ******Current best model saved:model_para/PEMS03/epoch_30.pth!
2023-05-22 19:45: Train Epoch 31: 0/490 Loss: 13.024388
2023-05-22 19:45: Train Epoch 31: 20/490 Loss: 13.564151
2023-05-22 19:45: Train Epoch 31: 40/490 Loss: 14.655057
2023-05-22 19:45: Train Epoch 31: 60/490 Loss: 12.328888
2023-05-22 19:45: Train Epoch 31: 80/490 Loss: 12.771636
2023-05-22 19:45: Train Epoch 31: 100/490 Loss: 13.154545
2023-05-22 19:45: Train Epoch 31: 120/490 Loss: 12.250998
2023-05-22 19:45: Train Epoch 31: 140/490 Loss: 13.536674
2023-05-22 19:45: Train Epoch 31: 160/490 Loss: 14.233843
2023-05-22 19:45: Train Epoch 31: 180/490 Loss: 13.711745
2023-05-22 19:45: Train Epoch 31: 200/490 Loss: 12.970555
2023-05-22 19:46: Train Epoch 31: 220/490 Loss: 13.495091
2023-05-22 19:46: Train Epoch 31: 240/490 Loss: 13.695589
2023-05-22 19:46: Train Epoch 31: 260/490 Loss: 13.701906
2023-05-22 19:46: Train Epoch 31: 280/490 Loss: 12.641993
2023-05-22 19:46: Train Epoch 31: 300/490 Loss: 14.202469
2023-05-22 19:46: Train Epoch 31: 320/490 Loss: 13.340471
2023-05-22 19:46: Train Epoch 31: 340/490 Loss: 13.452929
2023-05-22 19:46: Train Epoch 31: 360/490 Loss: 13.797689
2023-05-22 19:46: Train Epoch 31: 380/490 Loss: 13.578927
2023-05-22 19:46: Train Epoch 31: 400/490 Loss: 13.185740
2023-05-22 19:46: Train Epoch 31: 420/490 Loss: 14.414186
2023-05-22 19:46: Train Epoch 31: 440/490 Loss: 14.007344
2023-05-22 19:46: Train Epoch 31: 460/490 Loss: 14.226074
2023-05-22 19:46: Train Epoch 31: 480/490 Loss: 13.208589
2023-05-22 19:46: **********Train Epoch 31: averaged Loss: 13.209798, tf_ratio: 1.000000
2023-05-22 19:47: **********Val Epoch 31: average Loss: 14.255222
2023-05-22 19:47: Train Epoch 32: 0/490 Loss: 13.243858
2023-05-22 19:47: Train Epoch 32: 20/490 Loss: 13.385935
2023-05-22 19:47: Train Epoch 32: 40/490 Loss: 12.702679
2023-05-22 19:47: Train Epoch 32: 60/490 Loss: 12.332212
2023-05-22 19:47: Train Epoch 32: 80/490 Loss: 14.016263
2023-05-22 19:47: Train Epoch 32: 100/490 Loss: 13.277336
2023-05-22 19:47: Train Epoch 32: 120/490 Loss: 12.903813
2023-05-22 19:47: Train Epoch 32: 140/490 Loss: 13.913715
2023-05-22 19:47: Train Epoch 32: 160/490 Loss: 13.000140
2023-05-22 19:47: Train Epoch 32: 180/490 Loss: 13.333025
2023-05-22 19:47: Train Epoch 32: 200/490 Loss: 11.128245
2023-05-22 19:47: Train Epoch 32: 220/490 Loss: 14.298541
2023-05-22 19:48: Train Epoch 32: 240/490 Loss: 13.070214
2023-05-22 19:48: Train Epoch 32: 260/490 Loss: 12.464175
2023-05-22 19:48: Train Epoch 32: 280/490 Loss: 13.715619
2023-05-22 19:48: Train Epoch 32: 300/490 Loss: 13.300286
2023-05-22 19:48: Train Epoch 32: 320/490 Loss: 12.405520
2023-05-22 19:48: Train Epoch 32: 340/490 Loss: 11.832326
2023-05-22 19:48: Train Epoch 32: 360/490 Loss: 13.743145
2023-05-22 19:48: Train Epoch 32: 380/490 Loss: 14.386120
2023-05-22 19:48: Train Epoch 32: 400/490 Loss: 12.132664
2023-05-22 19:48: Train Epoch 32: 420/490 Loss: 12.461173
2023-05-22 19:48: Train Epoch 32: 440/490 Loss: 13.191718
2023-05-22 19:48: Train Epoch 32: 460/490 Loss: 13.171828
2023-05-22 19:48: Train Epoch 32: 480/490 Loss: 12.715768
2023-05-22 19:48: **********Train Epoch 32: averaged Loss: 13.150500, tf_ratio: 1.000000
2023-05-22 19:49: **********Val Epoch 32: average Loss: 14.219484
2023-05-22 19:49: ******Current best model saved:model_para/PEMS03/epoch_32.pth!
2023-05-22 19:49: Train Epoch 33: 0/490 Loss: 12.082912
2023-05-22 19:49: Train Epoch 33: 20/490 Loss: 14.004444
2023-05-22 19:49: Train Epoch 33: 40/490 Loss: 12.826153
2023-05-22 19:49: Train Epoch 33: 60/490 Loss: 13.245811
2023-05-22 19:49: Train Epoch 33: 80/490 Loss: 13.109173
2023-05-22 19:49: Train Epoch 33: 100/490 Loss: 14.113483
2023-05-22 19:49: Train Epoch 33: 120/490 Loss: 13.606495
2023-05-22 19:49: Train Epoch 33: 140/490 Loss: 13.193035
2023-05-22 19:49: Train Epoch 33: 160/490 Loss: 14.172034
2023-05-22 19:49: Train Epoch 33: 180/490 Loss: 12.816550
2023-05-22 19:49: Train Epoch 33: 200/490 Loss: 12.697358
2023-05-22 19:49: Train Epoch 33: 220/490 Loss: 13.757217
2023-05-22 19:50: Train Epoch 33: 240/490 Loss: 12.792768
2023-05-22 19:50: Train Epoch 33: 260/490 Loss: 13.041810
2023-05-22 19:50: Train Epoch 33: 280/490 Loss: 13.877741
2023-05-22 19:50: Train Epoch 33: 300/490 Loss: 14.085264
2023-05-22 19:50: Train Epoch 33: 320/490 Loss: 12.689568
2023-05-22 19:50: Train Epoch 33: 340/490 Loss: 13.834387
2023-05-22 19:50: Train Epoch 33: 360/490 Loss: 14.124605
2023-05-22 19:50: Train Epoch 33: 380/490 Loss: 13.602918
2023-05-22 19:50: Train Epoch 33: 400/490 Loss: 13.340269
2023-05-22 19:50: Train Epoch 33: 420/490 Loss: 12.824876
2023-05-22 19:50: Train Epoch 33: 440/490 Loss: 12.788022
2023-05-22 19:50: Train Epoch 33: 460/490 Loss: 13.886371
2023-05-22 19:50: Train Epoch 33: 480/490 Loss: 13.422421
2023-05-22 19:50: **********Train Epoch 33: averaged Loss: 13.115742, tf_ratio: 1.000000
2023-05-22 19:51: **********Val Epoch 33: average Loss: 14.339025
2023-05-22 19:51: Train Epoch 34: 0/490 Loss: 13.327095
2023-05-22 19:51: Train Epoch 34: 20/490 Loss: 14.570788
2023-05-22 19:51: Train Epoch 34: 40/490 Loss: 12.157063
2023-05-22 19:51: Train Epoch 34: 60/490 Loss: 12.914067
2023-05-22 19:51: Train Epoch 34: 80/490 Loss: 12.934374
2023-05-22 19:51: Train Epoch 34: 100/490 Loss: 12.895210
2023-05-22 19:51: Train Epoch 34: 120/490 Loss: 13.592857
2023-05-22 19:51: Train Epoch 34: 140/490 Loss: 12.674093
2023-05-22 19:51: Train Epoch 34: 160/490 Loss: 12.654928
2023-05-22 19:51: Train Epoch 34: 180/490 Loss: 13.108977
2023-05-22 19:51: Train Epoch 34: 200/490 Loss: 13.015611
2023-05-22 19:51: Train Epoch 34: 220/490 Loss: 13.984176
2023-05-22 19:51: Train Epoch 34: 240/490 Loss: 11.519027
2023-05-22 19:51: Train Epoch 34: 260/490 Loss: 14.354671
2023-05-22 19:52: Train Epoch 34: 280/490 Loss: 12.802456
2023-05-22 19:52: Train Epoch 34: 300/490 Loss: 13.856091
2023-05-22 19:52: Train Epoch 34: 320/490 Loss: 12.928029
2023-05-22 19:52: Train Epoch 34: 340/490 Loss: 11.975954
2023-05-22 19:52: Train Epoch 34: 360/490 Loss: 13.183604
2023-05-22 19:52: Train Epoch 34: 380/490 Loss: 14.172146
2023-05-22 19:52: Train Epoch 34: 400/490 Loss: 13.645862
2023-05-22 19:52: Train Epoch 34: 420/490 Loss: 14.454556
2023-05-22 19:52: Train Epoch 34: 440/490 Loss: 12.642589
2023-05-22 19:52: Train Epoch 34: 460/490 Loss: 14.491465
2023-05-22 19:52: Train Epoch 34: 480/490 Loss: 12.226514
2023-05-22 19:52: **********Train Epoch 34: averaged Loss: 13.081962, tf_ratio: 1.000000
2023-05-22 19:52: **********Val Epoch 34: average Loss: 14.244585
2023-05-22 19:52: Train Epoch 35: 0/490 Loss: 13.173096
2023-05-22 19:53: Train Epoch 35: 20/490 Loss: 12.943563
2023-05-22 19:53: Train Epoch 35: 40/490 Loss: 12.235473
2023-05-22 19:53: Train Epoch 35: 60/490 Loss: 13.348030
2023-05-22 19:53: Train Epoch 35: 80/490 Loss: 11.867118
2023-05-22 19:53: Train Epoch 35: 100/490 Loss: 12.691130
2023-05-22 19:53: Train Epoch 35: 120/490 Loss: 12.620071
2023-05-22 19:53: Train Epoch 35: 140/490 Loss: 13.391146
2023-05-22 19:53: Train Epoch 35: 160/490 Loss: 13.975842
2023-05-22 19:53: Train Epoch 35: 180/490 Loss: 13.609245
2023-05-22 19:53: Train Epoch 35: 200/490 Loss: 13.545890
2023-05-22 19:53: Train Epoch 35: 220/490 Loss: 13.257535
2023-05-22 19:53: Train Epoch 35: 240/490 Loss: 13.787021
2023-05-22 19:53: Train Epoch 35: 260/490 Loss: 12.715265
2023-05-22 19:53: Train Epoch 35: 280/490 Loss: 13.746414
2023-05-22 19:54: Train Epoch 35: 300/490 Loss: 13.123495
2023-05-22 19:54: Train Epoch 35: 320/490 Loss: 12.242089
2023-05-22 19:54: Train Epoch 35: 340/490 Loss: 14.085968
2023-05-22 19:54: Train Epoch 35: 360/490 Loss: 12.591362
2023-05-22 19:54: Train Epoch 35: 380/490 Loss: 13.172956
2023-05-22 19:54: Train Epoch 35: 400/490 Loss: 13.164603
2023-05-22 19:54: Train Epoch 35: 420/490 Loss: 13.609159
2023-05-22 19:54: Train Epoch 35: 440/490 Loss: 13.906106
2023-05-22 19:54: Train Epoch 35: 460/490 Loss: 13.706324
2023-05-22 19:54: Train Epoch 35: 480/490 Loss: 13.014786
2023-05-22 19:54: **********Train Epoch 35: averaged Loss: 13.094508, tf_ratio: 1.000000
2023-05-22 19:54: **********Val Epoch 35: average Loss: 14.336961
2023-05-22 19:54: Train Epoch 36: 0/490 Loss: 13.840709
2023-05-22 19:54: Train Epoch 36: 20/490 Loss: 12.674795
2023-05-22 19:55: Train Epoch 36: 40/490 Loss: 14.455208
2023-05-22 19:55: Train Epoch 36: 60/490 Loss: 11.904006
2023-05-22 19:55: Train Epoch 36: 80/490 Loss: 13.602616
2023-05-22 19:55: Train Epoch 36: 100/490 Loss: 12.577553
2023-05-22 19:55: Train Epoch 36: 120/490 Loss: 12.368314
2023-05-22 19:55: Train Epoch 36: 140/490 Loss: 12.432712
2023-05-22 19:55: Train Epoch 36: 160/490 Loss: 12.908719
2023-05-22 19:55: Train Epoch 36: 180/490 Loss: 13.184170
2023-05-22 19:55: Train Epoch 36: 200/490 Loss: 14.047473
2023-05-22 19:55: Train Epoch 36: 220/490 Loss: 13.232396
2023-05-22 19:55: Train Epoch 36: 240/490 Loss: 12.425680
2023-05-22 19:55: Train Epoch 36: 260/490 Loss: 13.277346
2023-05-22 19:55: Train Epoch 36: 280/490 Loss: 13.456869
2023-05-22 19:55: Train Epoch 36: 300/490 Loss: 12.879691
2023-05-22 19:56: Train Epoch 36: 320/490 Loss: 11.705273
2023-05-22 19:56: Train Epoch 36: 340/490 Loss: 13.336637
2023-05-22 19:56: Train Epoch 36: 360/490 Loss: 13.543411
2023-05-22 19:56: Train Epoch 36: 380/490 Loss: 13.469552
2023-05-22 19:56: Train Epoch 36: 400/490 Loss: 11.996631
2023-05-22 19:56: Train Epoch 36: 420/490 Loss: 13.530149
2023-05-22 19:56: Train Epoch 36: 440/490 Loss: 13.131931
2023-05-22 19:56: Train Epoch 36: 460/490 Loss: 11.423447
2023-05-22 19:56: Train Epoch 36: 480/490 Loss: 12.813887
2023-05-22 19:56: **********Train Epoch 36: averaged Loss: 13.030219, tf_ratio: 1.000000
2023-05-22 19:56: **********Val Epoch 36: average Loss: 14.168649
2023-05-22 19:56: ******Current best model saved:model_para/PEMS03/epoch_36.pth!
2023-05-22 19:56: Train Epoch 37: 0/490 Loss: 12.948520
2023-05-22 19:56: Train Epoch 37: 20/490 Loss: 13.004642
2023-05-22 19:56: Train Epoch 37: 40/490 Loss: 13.178916
2023-05-22 19:57: Train Epoch 37: 60/490 Loss: 12.060561
2023-05-22 19:57: Train Epoch 37: 80/490 Loss: 14.544016
2023-05-22 19:57: Train Epoch 37: 100/490 Loss: 13.182191
2023-05-22 19:57: Train Epoch 37: 120/490 Loss: 12.252743
2023-05-22 19:57: Train Epoch 37: 140/490 Loss: 12.562624
2023-05-22 19:57: Train Epoch 37: 160/490 Loss: 11.533304
2023-05-22 19:57: Train Epoch 37: 180/490 Loss: 14.044760
2023-05-22 19:57: Train Epoch 37: 200/490 Loss: 12.677252
2023-05-22 19:57: Train Epoch 37: 220/490 Loss: 12.419603
2023-05-22 19:57: Train Epoch 37: 240/490 Loss: 12.930519
2023-05-22 19:57: Train Epoch 37: 260/490 Loss: 14.575608
2023-05-22 19:57: Train Epoch 37: 280/490 Loss: 13.477795
2023-05-22 19:57: Train Epoch 37: 300/490 Loss: 12.979467
2023-05-22 19:57: Train Epoch 37: 320/490 Loss: 13.486322
2023-05-22 19:58: Train Epoch 37: 340/490 Loss: 12.936064
2023-05-22 19:58: Train Epoch 37: 360/490 Loss: 12.087516
2023-05-22 19:58: Train Epoch 37: 380/490 Loss: 13.122284
2023-05-22 19:58: Train Epoch 37: 400/490 Loss: 13.293427
2023-05-22 19:58: Train Epoch 37: 420/490 Loss: 12.731385
2023-05-22 19:58: Train Epoch 37: 440/490 Loss: 12.462211
2023-05-22 19:58: Train Epoch 37: 460/490 Loss: 13.884866
2023-05-22 19:58: Train Epoch 37: 480/490 Loss: 12.548986
2023-05-22 19:58: **********Train Epoch 37: averaged Loss: 13.006539, tf_ratio: 1.000000
2023-05-22 19:58: **********Val Epoch 37: average Loss: 14.172202
2023-05-22 19:58: Train Epoch 38: 0/490 Loss: 13.896309
2023-05-22 19:58: Train Epoch 38: 20/490 Loss: 12.189971
2023-05-22 19:58: Train Epoch 38: 40/490 Loss: 12.035655
2023-05-22 19:58: Train Epoch 38: 60/490 Loss: 13.906328
2023-05-22 19:59: Train Epoch 38: 80/490 Loss: 11.883111
2023-05-22 19:59: Train Epoch 38: 100/490 Loss: 12.589403
2023-05-22 19:59: Train Epoch 38: 120/490 Loss: 14.300918
2023-05-22 19:59: Train Epoch 38: 140/490 Loss: 11.422497
2023-05-22 19:59: Train Epoch 38: 160/490 Loss: 12.525688
2023-05-22 19:59: Train Epoch 38: 180/490 Loss: 13.590470
2023-05-22 19:59: Train Epoch 38: 200/490 Loss: 13.885299
2023-05-22 19:59: Train Epoch 38: 220/490 Loss: 13.309976
2023-05-22 19:59: Train Epoch 38: 240/490 Loss: 12.852820
2023-05-22 19:59: Train Epoch 38: 260/490 Loss: 12.850286
2023-05-22 19:59: Train Epoch 38: 280/490 Loss: 11.115762
2023-05-22 19:59: Train Epoch 38: 300/490 Loss: 12.083406
2023-05-22 19:59: Train Epoch 38: 320/490 Loss: 12.886194
2023-05-22 19:59: Train Epoch 38: 340/490 Loss: 12.878031
2023-05-22 20:00: Train Epoch 38: 360/490 Loss: 11.053389
2023-05-22 20:00: Train Epoch 38: 380/490 Loss: 12.728569
2023-05-22 20:00: Train Epoch 38: 400/490 Loss: 12.227184
2023-05-22 20:00: Train Epoch 38: 420/490 Loss: 11.943891
2023-05-22 20:00: Train Epoch 38: 440/490 Loss: 12.603806
2023-05-22 20:00: Train Epoch 38: 460/490 Loss: 12.721355
2023-05-22 20:00: Train Epoch 38: 480/490 Loss: 12.913515
2023-05-22 20:00: **********Train Epoch 38: averaged Loss: 12.987464, tf_ratio: 1.000000
2023-05-22 20:00: **********Val Epoch 38: average Loss: 14.337405
2023-05-22 20:00: Train Epoch 39: 0/490 Loss: 13.036090
2023-05-22 20:00: Train Epoch 39: 20/490 Loss: 12.824721
2023-05-22 20:00: Train Epoch 39: 40/490 Loss: 12.765212
2023-05-22 20:00: Train Epoch 39: 60/490 Loss: 12.788160
2023-05-22 20:01: Train Epoch 39: 80/490 Loss: 12.447722
2023-05-22 20:01: Train Epoch 39: 100/490 Loss: 13.297439
2023-05-22 20:01: Train Epoch 39: 120/490 Loss: 12.806467
2023-05-22 20:01: Train Epoch 39: 140/490 Loss: 13.473674
2023-05-22 20:01: Train Epoch 39: 160/490 Loss: 12.049145
2023-05-22 20:01: Train Epoch 39: 180/490 Loss: 12.160437
2023-05-22 20:01: Train Epoch 39: 200/490 Loss: 14.437419
2023-05-22 20:01: Train Epoch 39: 220/490 Loss: 12.642157
2023-05-22 20:01: Train Epoch 39: 240/490 Loss: 13.074232
2023-05-22 20:01: Train Epoch 39: 260/490 Loss: 13.166819
2023-05-22 20:01: Train Epoch 39: 280/490 Loss: 12.127822
2023-05-22 20:01: Train Epoch 39: 300/490 Loss: 13.479671
2023-05-22 20:01: Train Epoch 39: 320/490 Loss: 11.301286
2023-05-22 20:01: Train Epoch 39: 340/490 Loss: 12.770931
2023-05-22 20:02: Train Epoch 39: 360/490 Loss: 12.618502
2023-05-22 20:02: Train Epoch 39: 380/490 Loss: 12.578270
2023-05-22 20:02: Train Epoch 39: 400/490 Loss: 13.416908
2023-05-22 20:02: Train Epoch 39: 420/490 Loss: 13.666091
2023-05-22 20:02: Train Epoch 39: 440/490 Loss: 11.843131
2023-05-22 20:02: Train Epoch 39: 460/490 Loss: 12.776235
2023-05-22 20:02: Train Epoch 39: 480/490 Loss: 12.522944
2023-05-22 20:02: **********Train Epoch 39: averaged Loss: 12.946549, tf_ratio: 1.000000
2023-05-22 20:02: **********Val Epoch 39: average Loss: 14.242114
2023-05-22 20:02: Train Epoch 40: 0/490 Loss: 13.737785
2023-05-22 20:02: Train Epoch 40: 20/490 Loss: 13.628516
2023-05-22 20:02: Train Epoch 40: 40/490 Loss: 13.865639
2023-05-22 20:02: Train Epoch 40: 60/490 Loss: 12.386580
2023-05-22 20:02: Train Epoch 40: 80/490 Loss: 12.239307
2023-05-22 20:03: Train Epoch 40: 100/490 Loss: 13.765120
2023-05-22 20:03: Train Epoch 40: 120/490 Loss: 13.313268
2023-05-22 20:03: Train Epoch 40: 140/490 Loss: 14.206652
2023-05-22 20:03: Train Epoch 40: 160/490 Loss: 12.804038
2023-05-22 20:03: Train Epoch 40: 180/490 Loss: 14.087823
2023-05-22 20:03: Train Epoch 40: 200/490 Loss: 11.731387
2023-05-22 20:03: Train Epoch 40: 220/490 Loss: 11.684755
2023-05-22 20:03: Train Epoch 40: 240/490 Loss: 12.101849
2023-05-22 20:03: Train Epoch 40: 260/490 Loss: 13.160291
2023-05-22 20:03: Train Epoch 40: 280/490 Loss: 12.753671
2023-05-22 20:03: Train Epoch 40: 300/490 Loss: 13.483560
2023-05-22 20:03: Train Epoch 40: 320/490 Loss: 12.405853
2023-05-22 20:03: Train Epoch 40: 340/490 Loss: 12.989722
2023-05-22 20:03: Train Epoch 40: 360/490 Loss: 12.216293
2023-05-22 20:04: Train Epoch 40: 380/490 Loss: 13.525873
2023-05-22 20:04: Train Epoch 40: 400/490 Loss: 13.011910
2023-05-22 20:04: Train Epoch 40: 420/490 Loss: 12.777552
2023-05-22 20:04: Train Epoch 40: 440/490 Loss: 14.017171
2023-05-22 20:04: Train Epoch 40: 460/490 Loss: 12.578118
2023-05-22 20:04: Train Epoch 40: 480/490 Loss: 14.179489
2023-05-22 20:04: **********Train Epoch 40: averaged Loss: 12.918612, tf_ratio: 1.000000
2023-05-22 20:04: **********Val Epoch 40: average Loss: 14.207328
2023-05-22 20:04: Train Epoch 41: 0/490 Loss: 12.189833
2023-05-22 20:04: Train Epoch 41: 20/490 Loss: 12.350415
2023-05-22 20:04: Train Epoch 41: 40/490 Loss: 13.743346
2023-05-22 20:04: Train Epoch 41: 60/490 Loss: 13.186187
2023-05-22 20:04: Train Epoch 41: 80/490 Loss: 14.196692
2023-05-22 20:04: Train Epoch 41: 100/490 Loss: 11.991439
2023-05-22 20:05: Train Epoch 41: 120/490 Loss: 12.337322
2023-05-22 20:05: Train Epoch 41: 140/490 Loss: 13.212262
2023-05-22 20:05: Train Epoch 41: 160/490 Loss: 11.970377
2023-05-22 20:05: Train Epoch 41: 180/490 Loss: 13.271557
2023-05-22 20:05: Train Epoch 41: 200/490 Loss: 12.530495
2023-05-22 20:05: Train Epoch 41: 220/490 Loss: 12.796340
2023-05-22 20:05: Train Epoch 41: 240/490 Loss: 13.530169
2023-05-22 20:05: Train Epoch 41: 260/490 Loss: 13.204267
2023-05-22 20:05: Train Epoch 41: 280/490 Loss: 13.509741
2023-05-22 20:05: Train Epoch 41: 300/490 Loss: 14.913678
2023-05-22 20:05: Train Epoch 41: 320/490 Loss: 13.760704
2023-05-22 20:05: Train Epoch 41: 340/490 Loss: 13.065456
2023-05-22 20:05: Train Epoch 41: 360/490 Loss: 12.517740
2023-05-22 20:05: Train Epoch 41: 380/490 Loss: 12.920474
2023-05-22 20:06: Train Epoch 41: 400/490 Loss: 13.214971
2023-05-22 20:06: Train Epoch 41: 420/490 Loss: 13.163176
2023-05-22 20:06: Train Epoch 41: 440/490 Loss: 12.116750
2023-05-22 20:06: Train Epoch 41: 460/490 Loss: 14.147014
2023-05-22 20:06: Train Epoch 41: 480/490 Loss: 11.346147
2023-05-22 20:06: **********Train Epoch 41: averaged Loss: 12.899734, tf_ratio: 1.000000
2023-05-22 20:06: **********Val Epoch 41: average Loss: 14.151877
2023-05-22 20:06: ******Current best model saved:model_para/PEMS03/epoch_41.pth!
2023-05-22 20:06: Train Epoch 42: 0/490 Loss: 13.627355
2023-05-22 20:06: Train Epoch 42: 20/490 Loss: 12.579401
2023-05-22 20:06: Train Epoch 42: 40/490 Loss: 12.260500
2023-05-22 20:06: Train Epoch 42: 60/490 Loss: 13.774981
2023-05-22 20:06: Train Epoch 42: 80/490 Loss: 12.956390
2023-05-22 20:06: Train Epoch 42: 100/490 Loss: 13.000380
2023-05-22 20:07: Train Epoch 42: 120/490 Loss: 11.881688
2023-05-22 20:07: Train Epoch 42: 140/490 Loss: 12.935493
2023-05-22 20:07: Train Epoch 42: 160/490 Loss: 13.324682
2023-05-22 20:07: Train Epoch 42: 180/490 Loss: 13.297927
2023-05-22 20:07: Train Epoch 42: 200/490 Loss: 13.966594
2023-05-22 20:07: Train Epoch 42: 220/490 Loss: 13.263590
2023-05-22 20:07: Train Epoch 42: 240/490 Loss: 11.263191
2023-05-22 20:07: Train Epoch 42: 260/490 Loss: 12.061163
2023-05-22 20:07: Train Epoch 42: 280/490 Loss: 13.245178
2023-05-22 20:07: Train Epoch 42: 300/490 Loss: 12.568674
2023-05-22 20:07: Train Epoch 42: 320/490 Loss: 12.965615
2023-05-22 20:07: Train Epoch 42: 340/490 Loss: 13.341070
2023-05-22 20:07: Train Epoch 42: 360/490 Loss: 13.801572
2023-05-22 20:07: Train Epoch 42: 380/490 Loss: 12.869661
2023-05-22 20:08: Train Epoch 42: 400/490 Loss: 13.044457
2023-05-22 20:08: Train Epoch 42: 420/490 Loss: 12.350966
2023-05-22 20:08: Train Epoch 42: 440/490 Loss: 13.314976
2023-05-22 20:08: Train Epoch 42: 460/490 Loss: 12.662958
2023-05-22 20:08: Train Epoch 42: 480/490 Loss: 12.690380
2023-05-22 20:08: **********Train Epoch 42: averaged Loss: 12.894493, tf_ratio: 1.000000
2023-05-22 20:08: **********Val Epoch 42: average Loss: 14.128551
2023-05-22 20:08: ******Current best model saved:model_para/PEMS03/epoch_42.pth!
2023-05-22 20:08: Train Epoch 43: 0/490 Loss: 12.162333
2023-05-22 20:08: Train Epoch 43: 20/490 Loss: 13.168685
2023-05-22 20:08: Train Epoch 43: 40/490 Loss: 13.546349
2023-05-22 20:08: Train Epoch 43: 60/490 Loss: 12.751312
2023-05-22 20:08: Train Epoch 43: 80/490 Loss: 12.726829
2023-05-22 20:08: Train Epoch 43: 100/490 Loss: 13.597372
2023-05-22 20:08: Train Epoch 43: 120/490 Loss: 12.340271
2023-05-22 20:09: Train Epoch 43: 140/490 Loss: 11.842346
2023-05-22 20:09: Train Epoch 43: 160/490 Loss: 13.409452
2023-05-22 20:09: Train Epoch 43: 180/490 Loss: 12.205381
2023-05-22 20:09: Train Epoch 43: 200/490 Loss: 11.686985
2023-05-22 20:09: Train Epoch 43: 220/490 Loss: 12.065205
2023-05-22 20:09: Train Epoch 43: 240/490 Loss: 13.153565
2023-05-22 20:09: Train Epoch 43: 260/490 Loss: 11.528131
2023-05-22 20:09: Train Epoch 43: 280/490 Loss: 11.741173
2023-05-22 20:09: Train Epoch 43: 300/490 Loss: 12.983041
2023-05-22 20:09: Train Epoch 43: 320/490 Loss: 13.171634
2023-05-22 20:09: Train Epoch 43: 340/490 Loss: 12.662071
2023-05-22 20:09: Train Epoch 43: 360/490 Loss: 12.473472
2023-05-22 20:09: Train Epoch 43: 380/490 Loss: 11.669089
2023-05-22 20:09: Train Epoch 43: 400/490 Loss: 13.577728
2023-05-22 20:10: Train Epoch 43: 420/490 Loss: 12.608074
2023-05-22 20:10: Train Epoch 43: 440/490 Loss: 14.219945
2023-05-22 20:10: Train Epoch 43: 460/490 Loss: 12.693097
2023-05-22 20:10: Train Epoch 43: 480/490 Loss: 14.076640
2023-05-22 20:10: **********Train Epoch 43: averaged Loss: 12.874677, tf_ratio: 1.000000
2023-05-22 20:10: **********Val Epoch 43: average Loss: 14.133171
2023-05-22 20:10: Train Epoch 44: 0/490 Loss: 12.677775
2023-05-22 20:10: Train Epoch 44: 20/490 Loss: 12.121082
2023-05-22 20:10: Train Epoch 44: 40/490 Loss: 12.938853
2023-05-22 20:10: Train Epoch 44: 60/490 Loss: 14.131397
2023-05-22 20:10: Train Epoch 44: 80/490 Loss: 13.330222
2023-05-22 20:10: Train Epoch 44: 100/490 Loss: 12.862285
2023-05-22 20:10: Train Epoch 44: 120/490 Loss: 13.039188
2023-05-22 20:10: Train Epoch 44: 140/490 Loss: 12.593876
2023-05-22 20:11: Train Epoch 44: 160/490 Loss: 13.392848
2023-05-22 20:11: Train Epoch 44: 180/490 Loss: 13.373165
2023-05-22 20:11: Train Epoch 44: 200/490 Loss: 13.660254
2023-05-22 20:11: Train Epoch 44: 220/490 Loss: 13.013198
2023-05-22 20:11: Train Epoch 44: 240/490 Loss: 13.174890
2023-05-22 20:11: Train Epoch 44: 260/490 Loss: 13.065576
2023-05-22 20:11: Train Epoch 44: 280/490 Loss: 12.729703
2023-05-22 20:11: Train Epoch 44: 300/490 Loss: 12.694584
2023-05-22 20:11: Train Epoch 44: 320/490 Loss: 12.851693
2023-05-22 20:11: Train Epoch 44: 340/490 Loss: 11.597270
2023-05-22 20:11: Train Epoch 44: 360/490 Loss: 12.740164
2023-05-22 20:11: Train Epoch 44: 380/490 Loss: 12.784587
2023-05-22 20:11: Train Epoch 44: 400/490 Loss: 13.660332
2023-05-22 20:11: Train Epoch 44: 420/490 Loss: 12.908761
2023-05-22 20:12: Train Epoch 44: 440/490 Loss: 13.638904
2023-05-22 20:12: Train Epoch 44: 460/490 Loss: 11.838946
2023-05-22 20:12: Train Epoch 44: 480/490 Loss: 13.232080
2023-05-22 20:12: **********Train Epoch 44: averaged Loss: 12.870111, tf_ratio: 1.000000
2023-05-22 20:12: **********Val Epoch 44: average Loss: 14.231235
2023-05-22 20:12: Train Epoch 45: 0/490 Loss: 13.621232
2023-05-22 20:12: Train Epoch 45: 20/490 Loss: 13.776640
2023-05-22 20:12: Train Epoch 45: 40/490 Loss: 12.714037
2023-05-22 20:12: Train Epoch 45: 60/490 Loss: 12.962128
2023-05-22 20:12: Train Epoch 45: 80/490 Loss: 11.567727
2023-05-22 20:12: Train Epoch 45: 100/490 Loss: 13.917027
2023-05-22 20:12: Train Epoch 45: 120/490 Loss: 14.075185
2023-05-22 20:12: Train Epoch 45: 140/490 Loss: 13.929514
2023-05-22 20:12: Train Epoch 45: 160/490 Loss: 11.972563
2023-05-22 20:13: Train Epoch 45: 180/490 Loss: 12.611940
2023-05-22 20:13: Train Epoch 45: 200/490 Loss: 13.113235
2023-05-22 20:13: Train Epoch 45: 220/490 Loss: 12.143226
2023-05-22 20:13: Train Epoch 45: 240/490 Loss: 12.945234
2023-05-22 20:13: Train Epoch 45: 260/490 Loss: 13.334659
2023-05-22 20:13: Train Epoch 45: 280/490 Loss: 13.677993
2023-05-22 20:13: Train Epoch 45: 300/490 Loss: 13.555739
2023-05-22 20:13: Train Epoch 45: 320/490 Loss: 12.993971
2023-05-22 20:13: Train Epoch 45: 340/490 Loss: 13.239079
2023-05-22 20:13: Train Epoch 45: 360/490 Loss: 13.552336
2023-05-22 20:13: Train Epoch 45: 380/490 Loss: 12.499465
2023-05-22 20:13: Train Epoch 45: 400/490 Loss: 12.376766
2023-05-22 20:13: Train Epoch 45: 420/490 Loss: 12.150588
2023-05-22 20:14: Train Epoch 45: 440/490 Loss: 12.965983
2023-05-22 20:14: Train Epoch 45: 460/490 Loss: 12.763223
2023-05-22 20:14: Train Epoch 45: 480/490 Loss: 13.236341
2023-05-22 20:14: **********Train Epoch 45: averaged Loss: 12.835872, tf_ratio: 1.000000
2023-05-22 20:14: **********Val Epoch 45: average Loss: 14.106180
2023-05-22 20:14: ******Current best model saved:model_para/PEMS03/epoch_45.pth!
2023-05-22 20:14: Train Epoch 46: 0/490 Loss: 13.112164
2023-05-22 20:14: Train Epoch 46: 20/490 Loss: 13.282642
2023-05-22 20:14: Train Epoch 46: 40/490 Loss: 13.515831
2023-05-22 20:14: Train Epoch 46: 60/490 Loss: 12.470505
2023-05-22 20:14: Train Epoch 46: 80/490 Loss: 11.936844
2023-05-22 20:14: Train Epoch 46: 100/490 Loss: 13.618548
2023-05-22 20:14: Train Epoch 46: 120/490 Loss: 12.304955
2023-05-22 20:14: Train Epoch 46: 140/490 Loss: 12.887156
2023-05-22 20:14: Train Epoch 46: 160/490 Loss: 13.516758
2023-05-22 20:15: Train Epoch 46: 180/490 Loss: 12.922103
2023-05-22 20:15: Train Epoch 46: 200/490 Loss: 12.461684
2023-05-22 20:15: Train Epoch 46: 220/490 Loss: 12.977201
2023-05-22 20:15: Train Epoch 46: 240/490 Loss: 13.110231
2023-05-22 20:15: Train Epoch 46: 260/490 Loss: 12.249493
2023-05-22 20:15: Train Epoch 46: 280/490 Loss: 11.761720
2023-05-22 20:15: Train Epoch 46: 300/490 Loss: 11.557330
2023-05-22 20:15: Train Epoch 46: 320/490 Loss: 13.253913
2023-05-22 20:15: Train Epoch 46: 340/490 Loss: 13.267174
2023-05-22 20:15: Train Epoch 46: 360/490 Loss: 11.855806
2023-05-22 20:15: Train Epoch 46: 380/490 Loss: 12.315033
2023-05-22 20:15: Train Epoch 46: 400/490 Loss: 11.389172
2023-05-22 20:15: Train Epoch 46: 420/490 Loss: 12.135262
2023-05-22 20:15: Train Epoch 46: 440/490 Loss: 13.196497
2023-05-22 20:16: Train Epoch 46: 460/490 Loss: 12.248950
2023-05-22 20:16: Train Epoch 46: 480/490 Loss: 13.174066
2023-05-22 20:16: **********Train Epoch 46: averaged Loss: 12.787807, tf_ratio: 1.000000
2023-05-22 20:16: **********Val Epoch 46: average Loss: 14.109948
2023-05-22 20:16: Train Epoch 47: 0/490 Loss: 11.941377
2023-05-22 20:16: Train Epoch 47: 20/490 Loss: 12.620093
2023-05-22 20:16: Train Epoch 47: 40/490 Loss: 12.678842
2023-05-22 20:16: Train Epoch 47: 60/490 Loss: 13.415357
2023-05-22 20:16: Train Epoch 47: 80/490 Loss: 13.230053
2023-05-22 20:16: Train Epoch 47: 100/490 Loss: 11.685458
2023-05-22 20:16: Train Epoch 47: 120/490 Loss: 13.715768
2023-05-22 20:16: Train Epoch 47: 140/490 Loss: 12.549171
2023-05-22 20:16: Train Epoch 47: 160/490 Loss: 13.293572
2023-05-22 20:16: Train Epoch 47: 180/490 Loss: 13.376888
2023-05-22 20:17: Train Epoch 47: 200/490 Loss: 13.440537
2023-05-22 20:17: Train Epoch 47: 220/490 Loss: 12.588211
2023-05-22 20:17: Train Epoch 47: 240/490 Loss: 13.799385
2023-05-22 20:17: Train Epoch 47: 260/490 Loss: 14.076974
2023-05-22 20:17: Train Epoch 47: 280/490 Loss: 13.093472
2023-05-22 20:17: Train Epoch 47: 300/490 Loss: 13.603949
2023-05-22 20:17: Train Epoch 47: 320/490 Loss: 12.482013
2023-05-22 20:17: Train Epoch 47: 340/490 Loss: 14.791272
2023-05-22 20:17: Train Epoch 47: 360/490 Loss: 12.806159
2023-05-22 20:17: Train Epoch 47: 380/490 Loss: 11.383087
2023-05-22 20:17: Train Epoch 47: 400/490 Loss: 13.115571
2023-05-22 20:17: Train Epoch 47: 420/490 Loss: 13.142061
2023-05-22 20:17: Train Epoch 47: 440/490 Loss: 13.920105
2023-05-22 20:17: Train Epoch 47: 460/490 Loss: 12.925439
2023-05-22 20:18: Train Epoch 47: 480/490 Loss: 12.902034
2023-05-22 20:18: **********Train Epoch 47: averaged Loss: 12.778339, tf_ratio: 1.000000
2023-05-22 20:18: **********Val Epoch 47: average Loss: 14.279796
2023-05-22 20:18: Train Epoch 48: 0/490 Loss: 11.920415
2023-05-22 20:18: Train Epoch 48: 20/490 Loss: 12.831885
2023-05-22 20:18: Train Epoch 48: 40/490 Loss: 12.903131
2023-05-22 20:18: Train Epoch 48: 60/490 Loss: 14.108078
2023-05-22 20:18: Train Epoch 48: 80/490 Loss: 12.610615
2023-05-22 20:18: Train Epoch 48: 100/490 Loss: 12.442514
2023-05-22 20:18: Train Epoch 48: 120/490 Loss: 11.992664
2023-05-22 20:18: Train Epoch 48: 140/490 Loss: 12.418106
2023-05-22 20:18: Train Epoch 48: 160/490 Loss: 13.179165
2023-05-22 20:18: Train Epoch 48: 180/490 Loss: 12.293211
2023-05-22 20:19: Train Epoch 48: 200/490 Loss: 11.701315
2023-05-22 20:19: Train Epoch 48: 220/490 Loss: 14.008970
2023-05-22 20:19: Train Epoch 48: 240/490 Loss: 12.216634
2023-05-22 20:19: Train Epoch 48: 260/490 Loss: 10.846541
2023-05-22 20:19: Train Epoch 48: 280/490 Loss: 12.995422
2023-05-22 20:19: Train Epoch 48: 300/490 Loss: 12.816507
2023-05-22 20:19: Train Epoch 48: 320/490 Loss: 13.222264
2023-05-22 20:19: Train Epoch 48: 340/490 Loss: 12.714994
2023-05-22 20:19: Train Epoch 48: 360/490 Loss: 12.138292
2023-05-22 20:19: Train Epoch 48: 380/490 Loss: 14.078472
2023-05-22 20:19: Train Epoch 48: 400/490 Loss: 12.786020
2023-05-22 20:19: Train Epoch 48: 420/490 Loss: 12.679631
2023-05-22 20:19: Train Epoch 48: 440/490 Loss: 13.586146
2023-05-22 20:19: Train Epoch 48: 460/490 Loss: 12.208008
2023-05-22 20:20: Train Epoch 48: 480/490 Loss: 12.993221
2023-05-22 20:20: **********Train Epoch 48: averaged Loss: 12.772461, tf_ratio: 1.000000
2023-05-22 20:20: **********Val Epoch 48: average Loss: 14.119290
2023-05-22 20:20: Train Epoch 49: 0/490 Loss: 11.676719
2023-05-22 20:20: Train Epoch 49: 20/490 Loss: 12.767381
2023-05-22 20:20: Train Epoch 49: 40/490 Loss: 12.403905
2023-05-22 20:20: Train Epoch 49: 60/490 Loss: 13.914141
2023-05-22 20:20: Train Epoch 49: 80/490 Loss: 11.909751
2023-05-22 20:20: Train Epoch 49: 100/490 Loss: 11.863029
2023-05-22 20:20: Train Epoch 49: 120/490 Loss: 12.869843
2023-05-22 20:20: Train Epoch 49: 140/490 Loss: 13.109848
2023-05-22 20:20: Train Epoch 49: 160/490 Loss: 12.336431
2023-05-22 20:20: Train Epoch 49: 180/490 Loss: 12.882131
2023-05-22 20:20: Train Epoch 49: 200/490 Loss: 13.140554
2023-05-22 20:21: Train Epoch 49: 220/490 Loss: 13.846625
2023-05-22 20:21: Train Epoch 49: 240/490 Loss: 13.264915
2023-05-22 20:21: Train Epoch 49: 260/490 Loss: 12.785097
2023-05-22 20:21: Train Epoch 49: 280/490 Loss: 14.090267
2023-05-22 20:21: Train Epoch 49: 300/490 Loss: 12.425748
2023-05-22 20:21: Train Epoch 49: 320/490 Loss: 11.439492
2023-05-22 20:21: Train Epoch 49: 340/490 Loss: 11.964601
2023-05-22 20:21: Train Epoch 49: 360/490 Loss: 13.747014
2023-05-22 20:21: Train Epoch 49: 380/490 Loss: 11.777598
2023-05-22 20:21: Train Epoch 49: 400/490 Loss: 13.660259
2023-05-22 20:21: Train Epoch 49: 420/490 Loss: 13.278763
2023-05-22 20:21: Train Epoch 49: 440/490 Loss: 14.194693
2023-05-22 20:21: Train Epoch 49: 460/490 Loss: 14.505437
2023-05-22 20:21: Train Epoch 49: 480/490 Loss: 12.946031
2023-05-22 20:21: **********Train Epoch 49: averaged Loss: 12.748163, tf_ratio: 1.000000
2023-05-22 20:22: **********Val Epoch 49: average Loss: 14.183534
2023-05-22 20:22: Train Epoch 50: 0/490 Loss: 13.545060
2023-05-22 20:22: Train Epoch 50: 20/490 Loss: 12.170157
2023-05-22 20:22: Train Epoch 50: 40/490 Loss: 13.445082
2023-05-22 20:22: Train Epoch 50: 60/490 Loss: 11.848273
2023-05-22 20:22: Train Epoch 50: 80/490 Loss: 12.889874
2023-05-22 20:22: Train Epoch 50: 100/490 Loss: 12.461005
2023-05-22 20:22: Train Epoch 50: 120/490 Loss: 12.584054
2023-05-22 20:22: Train Epoch 50: 140/490 Loss: 11.799607
2023-05-22 20:22: Train Epoch 50: 160/490 Loss: 12.923846
2023-05-22 20:22: Train Epoch 50: 180/490 Loss: 11.914415
2023-05-22 20:22: Train Epoch 50: 200/490 Loss: 12.400928
2023-05-22 20:22: Train Epoch 50: 220/490 Loss: 13.889037
2023-05-22 20:23: Train Epoch 50: 240/490 Loss: 12.687116
2023-05-22 20:23: Train Epoch 50: 260/490 Loss: 13.323126
2023-05-22 20:23: Train Epoch 50: 280/490 Loss: 11.790720
2023-05-22 20:23: Train Epoch 50: 300/490 Loss: 12.236200
2023-05-22 20:23: Train Epoch 50: 320/490 Loss: 12.309768
2023-05-22 20:23: Train Epoch 50: 340/490 Loss: 13.988169
2023-05-22 20:23: Train Epoch 50: 360/490 Loss: 12.265266
2023-05-22 20:23: Train Epoch 50: 380/490 Loss: 12.535311
2023-05-22 20:23: Train Epoch 50: 400/490 Loss: 12.199935
2023-05-22 20:23: Train Epoch 50: 420/490 Loss: 12.429902
2023-05-22 20:23: Train Epoch 50: 440/490 Loss: 14.145190
2023-05-22 20:23: Train Epoch 50: 460/490 Loss: 12.515422
2023-05-22 20:23: Train Epoch 50: 480/490 Loss: 12.533392
2023-05-22 20:23: **********Train Epoch 50: averaged Loss: 12.733388, tf_ratio: 1.000000
2023-05-22 20:24: **********Val Epoch 50: average Loss: 14.166945
2023-05-22 20:24: Train Epoch 51: 0/490 Loss: 13.560367
2023-05-22 20:24: Train Epoch 51: 20/490 Loss: 12.580164
2023-05-22 20:24: Train Epoch 51: 40/490 Loss: 13.791637
2023-05-22 20:24: Train Epoch 51: 60/490 Loss: 12.016172
2023-05-22 20:24: Train Epoch 51: 80/490 Loss: 13.221105
2023-05-22 20:24: Train Epoch 51: 100/490 Loss: 11.427548
2023-05-22 20:24: Train Epoch 51: 120/490 Loss: 13.892752
2023-05-22 20:24: Train Epoch 51: 140/490 Loss: 12.063763
2023-05-22 20:24: Train Epoch 51: 160/490 Loss: 12.969854
